{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Starling Tutorial \u00b6 Starling Tutorial Introduction What is Starling What Will I learn In This Tutorial The Tutorial Task Scenario How To Use This Tutorial Contents Introduction \u00b6 What is Starling \u00b6 Starling is an end to end, modular, containerised UAV infrastucture designed to facilitate the local development, testing and deployment of Single and Multi-UAV systems from simulation to the Bristol Robotics Lab Flight Arena (and hopefully beyond). It will hopefully allow for a more approachable development workflow to enable more researchers to fly UAVs in a safe, reproducable and controllable manner. This tutorial is intended to demonstrate how to use Starling to develop and deploy a multi-uav controller. What Will I learn In This Tutorial \u00b6 In this tutorial you will The Tutorial Task Scenario \u00b6 You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind. How To Use This Tutorial \u00b6 This tutorial Contents \u00b6","title":"Starling Tutorial"},{"location":"#starling-tutorial","text":"Starling Tutorial Introduction What is Starling What Will I learn In This Tutorial The Tutorial Task Scenario How To Use This Tutorial Contents","title":"Starling Tutorial"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#what-is-starling","text":"Starling is an end to end, modular, containerised UAV infrastucture designed to facilitate the local development, testing and deployment of Single and Multi-UAV systems from simulation to the Bristol Robotics Lab Flight Arena (and hopefully beyond). It will hopefully allow for a more approachable development workflow to enable more researchers to fly UAVs in a safe, reproducable and controllable manner. This tutorial is intended to demonstrate how to use Starling to develop and deploy a multi-uav controller.","title":"What is Starling"},{"location":"#what-will-i-learn-in-this-tutorial","text":"In this tutorial you will","title":"What Will I learn In This Tutorial"},{"location":"#the-tutorial-task-scenario","text":"You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind.","title":"The Tutorial Task Scenario"},{"location":"#how-to-use-this-tutorial","text":"This tutorial","title":"How To Use This Tutorial"},{"location":"#contents","text":"","title":"Contents"},{"location":"brl/","text":"Bristol Robotics Laboratory Flying Arena \u00b6","title":"10. Bristol Robotics Laboratory Flying Arena"},{"location":"brl/#bristol-robotics-laboratory-flying-arena","text":"","title":"Bristol Robotics Laboratory Flying Arena"},{"location":"brl_flight/","text":"Flying your controllers in the Flying Arena \u00b6","title":"11. Flying your controllers in the Flying Arena"},{"location":"brl_flight/#flying-your-controllers-in-the-flying-arena","text":"","title":"Flying your controllers in the Flying Arena"},{"location":"cpp_example_dev/","text":"Developing the example controller with ROS2 in CPP \u00b6 Finally, the bit you have all been waiting for! In this tutorial, we will take you through how to develop and build the controller for the example scenario. This page is for the CPP controller in particular. By the end, you should have have a controller ready for testing. Developing the example controller with ROS2 in CPP Very Very Quick Intro To CPP Overview of the Controller Template Controller Core Functionality Controller Communication with MAVROS Controller User Implemented Functionality A Solution to the Scenario Useful Tips for Implementation Getting the actual current theta Creating and Publishing Messages Angular Velocity and Position Theta to position Sending Vehicle Setpoint Next Steps Very Very Quick Intro To CPP \u00b6 By the time the launch of this tutorial comes by, we may or may not have an equivalent Python tutorial. Therefore we provide a very very very quick intro to the bits of CPP you need to know about for this tutorial. We recommend you check out online tutorials on CPP for a much more complete introduction! So in no particular order: CPP is an Object Orientated-ish Language, so we have the idea of Classes which contain member variables and member functions. As a result we also have the concept of inheritance, where a child class and inherit the functionality and variables from its parent class. In ROS2, every rosnode class inherits from the rclcpp (ROS CPP Library) Node class. class UAVController : public rclcpp::Node { public: UAVController(); void reset(); private: std::string vehicle_id = \"vehicle_1\"; } In CPP (unlike Python), it is standard practice to split the Declaration of functions and variables from the Implementation of those same functions and variables. Reasons includes space saving, verboseness and other things - look it up. This is one of the reasons CPP code is split between header (.hpp) files and source (.cpp) files. Header files contain all of the class and function declarations, like the example shown above. The syntax for a function declaration is <return type> <function_name>(<function arguments>); . The syntax to create a variable is <variable type> variable_name; , and can either be immediately assigned to or assigned later. Note that CPP is typed , which means that all functions and variables must specify what they intend to take as argument, return or be explictly (unlike Python). Source files contain the implementation of the class and functions which have been declared in the assocated header file (imported with #include header.hpp ). The following shows the implementation of the reset function in the source file, corresponding to the class in the header. Within the implementation, class variables can be used by accessing the this variable. Note that instead of a . , an arrow -> is used. An arrow is needed to access anything which is of a pointer type sth_ptr (the this variable is a pointer to itself). This should be enough for now - read up for much more detail) . void UAVController::reset(){ // ... some implementation this->vehicle_id = \"default_vehicle_name\"; } As with most languages, CPP has the standard control flow operations - if, for, while, continue, return etc etc that you would see in most other languages. Hopefully you can infer how these, and the various other CPP elements work from reading the code! Good luck! :D Overview of the Controller Template \u00b6 Let us start by examining the CPP onboard controller in more detail. You can open up the project in visual studio code by navigating into your starling application directory and running code . As shown in the creating a starling project tutorial , the CPP onboard controller has the following structure: |-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp We gave an overview there, but we didn't provide any details on what exactly the CPP files are doing! So we now go into more detail. Controller Core Functionality \u00b6 In addition to performing the application, this controller must take care of a number of normal functions before and after executing the actions of the application. This includes the following actions: Ensuring and checking that the vehicle is receiving telemetry. Arming and Disarming the Vehicle before and after flight Taking off from the ground and Landing safely Going to the start location of the given task. Taking instruction (such as go, abort and estop) and safely reacting to them from users. It can be thought that the order and usage of these actions are fairly consistent over a large number of possible applications. Therefore this controller bundles these up as standard functionality within the main execution of the node. In further details, the main.hpp and main.cpp files define a UAVController rosnode class. Within this class, after initialisation, a timer is used to run a main operating loop function over and over at a fixed interval (10hz by default). Our controller makes use of a finite state machine model to manage the control flow through the various states mentioned above. This fsm is shown in the diagram below. The Rectangular boxes (apart from the red ones) all depict States of this fsm. Each state requires a number of orange actions to completed or checks to pass before it can move onto the next state. The green states also include live checks for if the vehicle is armed and in the correct mode for offboard flight, as the vehicle will be in the air. The FSM also contains failure states for any of the checks where the vehicle which immediately go to Stop, and therefore immediately land and make safe in the air. The functionality of this state machine is encoded within the stateMachine(Time stamp) function, and is triggered by a Ros Timer running at 10hz ( this->execution_timer ). The States are defined in state.hpp . From an implementation standpoint, since the state machine has to run continuously, any called function cannot internally loop indefinitely and must execute and immediately exit. Traditionally FSMs switch states through the use of a large set of binary variables. In this particular application, this felt very verbose, and so we use boolean returning execution functions as our state machine checks. For example the Takeoff check calls to see whether this->smTakeoffVehicle(stamp) (main.cpp:246) returns true. case State::TAKEOFF: this->smOffboardArmed(stamp); if(!this->smTakeoffVehicle(stamp)) { RCLCPP_INFO(this->get_logger(), \"Waiting for Takeoff\"); } However looking at this function, it itself performs the takeoff procedure to a given height, always returning false, unless the vehicle is at its takeoff location. Controller Communication with MAVROS \u00b6 Now we have the controller architecture in play, how does this controller actually talk to the vehicle! At the bottom of main.hpp you should see a whole bunch of Ros Publishers and Subscribers being declared (note how they are pointers). These pubs and subs are initialised within the class constructor/initialiser in main.cpp:67-97 . In order to detect arming and mode, we subscribe to mavros/state , and in order to get the local cartesian position and orientation of the vehicle, we also get mavros/local_position/pose . These both give us a constant stream of data which we save into variables this->vehicle_state and this->vehicle_local_position . In order to send position commands to the vehicle, we set up a publisher to mavros/setpoint_position/local and use the sendSetpointPositionPose(stamp, geometry_msgs::msg::PoseStamped) function to publish setpoints to the autopilot. The translated MAVLINK commands then tell the drone to go to that location and orienation immediately. Therefore in a number of places, we make use of interpolators to ensure that the vehicle can move from its location to any other at safe velocities and rates. Otherwise, the drone will ramp up to maximum velocity to go to far away locations which can be quite dangerous! That is why the CD3 interpolate library is included by default. Controller User Implemented Functionality \u00b6 In creating this template, it was our intention to make the user developer experience as pleasant as possible. As previously mentioned we identified that the majority of drone functionality was mostly fixed between different applications, with only the application differing. In terms of our state machine, that corresponds to only executing application based at initialisation and during the execute state. We therefore decided to abstract this out into its own class of UserController within trajectory.hpp and trajectory.cpp . class UserController { public: UserController(UAVController *node); // Reset this controller void reset(); // User Controller Checking If The Start Location is Registered bool smReady(const rclcpp::Time& stamp); // User Controller Execute One Control Loop bool smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed); private: // ROS Helper Functions rclcpp::Logger get_logger(); rclcpp::Time now(); // The ROSnode itself UAVController* node; // User variables ... } The UserController only has 3 functions of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) which correspond with the parts of the State Machine which are important to the user. The other important variable is the node . This class is not a node in itself (A node cannot run another node). Therefore during initialisation, we pass in the main UAVController node so that we can call useful functions later. So how does UserController fit into the main node? UserController is actually declared in main.hpp:99 and initialised in main.cpp:100 . Doing a ctrl+f and searching for this->user_controller you can see the places where it gets called, and they are as described above. So then, where does the user code go! The code you write for your own applications therefore goes in two places: New functions and variables to do with your code are declared below the node variable in controller.hpp Implementations of these functions, as well as your implementations of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) should be provided into the gaps available in controller.cpp . Usefully for this example, we have already provided 80% of the implementation, including publishers and subscribers and the implmentation of all the core functions except smExecute(stamp, time_elapsed) which will be discussed below and left as an exercise for the reader. After the next section, have a read through controller.hpp and controller.cpp and try and follow the logic to see if it makes sense. A Solution to the Scenario \u00b6 You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind. For the purpose of this tutorial, we have created this particular method of solving the problem, and other ways definitely exist! Unless you are confident in your ability, we ask that you follow for now :) We take the approach of characterising a vehicle's position solely based on its angle theta, with the following steps: Server sends how many drones are on the network every few seconds and labels drones from 0+ (Uses NotifyVehicles msg) Drones use id to work out starting location around the circle Wait for GO to Takeoff Wait for valid start location and GO to move to start locations Wait for GO to continue Vehicle flies around in a circle During flight, vehicle sends its own theta every second to server (Uses TargetAngle msg) Server responds with angle it should be at right now with respect to other vehicles (Uses TargetAngle msg) A simple brute force algorithm is to imagine each vehicle was correct and calculate ideal locations of all other vehicles. Then return the average of each ideal location for each drone. Drones then proportionally change velocity based on angle disparity. Usefully for you all, the tutorial already implements all of these functions except for part 5 and 6 which you will need to implement. Within controller.cpp your goal is to fill in steps 5 and 6 into the smExecute function. bool UserController::smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed) { // Get Time Elapsed Since State Change double time_elapsed_sec = time_elapsed.seconds(); // Current Vehicle Location geometry_msgs::msg::PoseStamped current_pos = this->node->vehicle_local_position; /* * * Implement Your Solution Here * */ // State Machine never exists by giving false. return false; } As you're developing, dont forget to run make often to compile and build your code! This will help you catch syntax errors and other bugs as your go. You may also want to try out some of the local testing instructions in the next tutorial and come back and implement other bits. Useful Tips for Implementation \u00b6 Now we pride some guidelines and tips for implementing the solution yourself. Remember to have a look through the available variables. You can access these variables using the this->(myvariabe) functions. Getting the actual current theta \u00b6 The algorithm requires sending the vehicles actual theta to the server for processing. The actual theta of the vehicle has to be calculated from the x,y location of the vehicle with respect to the origin location of the vehicle. Note: that many mathematics functions such as atan2(x,y) , sin(x) , cos(x) are available as is in these formats. View spoilers and code double current_theta = atan2(current_pos->pose.position.y - this->origin.y, current_pos->pose.position.x - this->origin.x); Creating and Publishing Messages \u00b6 The server uses the TargetAngle and NotifyVehicle messages to communicate with the vehicle. The vehicle then sends TargetAngle messages back to the server each execution step. Have a look at the TargetAngle msg inside your custom msgs folder. You can create a message in cpp using the following syntax: target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; ... Where the msg fields can be filled in by using the msg.<field> = ... notation. Once you have created the correct message for a particular publisher, you can publish the message by using: this->my_publisher->publish(msg); Have a look for which publisher you should be publishing with. View spoilers and code target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; msg.time = stamp; msg.theta = current_theta; this->notify_angle_pub->publish(msg); Angular Velocity and Position \u00b6 Now we've sent the actual theta information to the server, we should now calculate where the vehicle should go. We are doing this based on the time that has been elapsed and the vehicle velocity to calculate a setpoint based on where the vehicle should be right now. Therefore you will first need to calculate the angular velocity to see what angle the vehicle should be currently at. Secondly you can then find the actual theta by calculating the number of radians travelled in addition to the start location of the vehicle. You should set the calculated theta to the this->vehicle_setpoint_theta member variable. Note: You can use the fmod function to do a floating point modulo operation. View spoilers and code // Get Angular (Theta) Velocity double angular_vel = this->vehicle_velocity / circle_radius; // Amount of theta vehicle should have moved w.r.t to start location this->vehicle_setpoint_theta = fmod(this->vehicle_start_theta + time_elapsed_sec * angular_vel, 2*M_PI); Theta to position \u00b6 Now you have calculated the setpoint theta, we now need to work out the cartesian (x,y,z) coordinate for the drone to fly to using its internal position control. This can be done through trigonometry: $$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta)$$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta) But dont forget about \\(z\\) z and yaw too! View spoilers and code // Convert theta to coordinate location double x = this->circle_radius * cos(this->vehicle_setpoint_theta) + this->origin.x; double y = this->circle_radius * sin(this->vehicle_setpoint_theta) + this->origin.y; double z = this->height + this->origin.z; double yaw = this->vehicle_setpoint_theta; Sending Vehicle Setpoint \u00b6 Finally with the position the vehicle should visit calculated, you can send off the Setpoint position for the vehicle to execute using the node's built in function. // Tell Vehicle to go to coordinate location this->node->sendSetpointPositionCoordinate(stamp, x, y, z, yaw); // Log this using the following function RCLCPP_INFO(this->get_logger(), \"Vehicle going to (%f, %f, %f), theta: %f\", x, y, z, yaw Next Steps \u00b6 Congrats you have hopefully either begun or completed the implementation of a controller which should hopefully solve the example problem. You should now have a decent understanding of how the core UAV rosnode controller template is constructed. Have a look at the implementation for the offboard controller and see if you can match it's functionality with the algorithm steps shown above. See if you can identify how it connects with the controller you have just written. However now, we need to check its functionality - is it actually working or doing what we expect? We will cover how to perform local development and testing in the next chapter.","title":"6. Developing the example controller with ROS2 in CPP"},{"location":"cpp_example_dev/#developing-the-example-controller-with-ros2-in-cpp","text":"Finally, the bit you have all been waiting for! In this tutorial, we will take you through how to develop and build the controller for the example scenario. This page is for the CPP controller in particular. By the end, you should have have a controller ready for testing. Developing the example controller with ROS2 in CPP Very Very Quick Intro To CPP Overview of the Controller Template Controller Core Functionality Controller Communication with MAVROS Controller User Implemented Functionality A Solution to the Scenario Useful Tips for Implementation Getting the actual current theta Creating and Publishing Messages Angular Velocity and Position Theta to position Sending Vehicle Setpoint Next Steps","title":"Developing the example controller with ROS2 in CPP"},{"location":"cpp_example_dev/#very-very-quick-intro-to-cpp","text":"By the time the launch of this tutorial comes by, we may or may not have an equivalent Python tutorial. Therefore we provide a very very very quick intro to the bits of CPP you need to know about for this tutorial. We recommend you check out online tutorials on CPP for a much more complete introduction! So in no particular order: CPP is an Object Orientated-ish Language, so we have the idea of Classes which contain member variables and member functions. As a result we also have the concept of inheritance, where a child class and inherit the functionality and variables from its parent class. In ROS2, every rosnode class inherits from the rclcpp (ROS CPP Library) Node class. class UAVController : public rclcpp::Node { public: UAVController(); void reset(); private: std::string vehicle_id = \"vehicle_1\"; } In CPP (unlike Python), it is standard practice to split the Declaration of functions and variables from the Implementation of those same functions and variables. Reasons includes space saving, verboseness and other things - look it up. This is one of the reasons CPP code is split between header (.hpp) files and source (.cpp) files. Header files contain all of the class and function declarations, like the example shown above. The syntax for a function declaration is <return type> <function_name>(<function arguments>); . The syntax to create a variable is <variable type> variable_name; , and can either be immediately assigned to or assigned later. Note that CPP is typed , which means that all functions and variables must specify what they intend to take as argument, return or be explictly (unlike Python). Source files contain the implementation of the class and functions which have been declared in the assocated header file (imported with #include header.hpp ). The following shows the implementation of the reset function in the source file, corresponding to the class in the header. Within the implementation, class variables can be used by accessing the this variable. Note that instead of a . , an arrow -> is used. An arrow is needed to access anything which is of a pointer type sth_ptr (the this variable is a pointer to itself). This should be enough for now - read up for much more detail) . void UAVController::reset(){ // ... some implementation this->vehicle_id = \"default_vehicle_name\"; } As with most languages, CPP has the standard control flow operations - if, for, while, continue, return etc etc that you would see in most other languages. Hopefully you can infer how these, and the various other CPP elements work from reading the code! Good luck! :D","title":"Very Very Quick Intro To CPP"},{"location":"cpp_example_dev/#overview-of-the-controller-template","text":"Let us start by examining the CPP onboard controller in more detail. You can open up the project in visual studio code by navigating into your starling application directory and running code . As shown in the creating a starling project tutorial , the CPP onboard controller has the following structure: |-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp We gave an overview there, but we didn't provide any details on what exactly the CPP files are doing! So we now go into more detail.","title":"Overview of the Controller Template"},{"location":"cpp_example_dev/#controller-core-functionality","text":"In addition to performing the application, this controller must take care of a number of normal functions before and after executing the actions of the application. This includes the following actions: Ensuring and checking that the vehicle is receiving telemetry. Arming and Disarming the Vehicle before and after flight Taking off from the ground and Landing safely Going to the start location of the given task. Taking instruction (such as go, abort and estop) and safely reacting to them from users. It can be thought that the order and usage of these actions are fairly consistent over a large number of possible applications. Therefore this controller bundles these up as standard functionality within the main execution of the node. In further details, the main.hpp and main.cpp files define a UAVController rosnode class. Within this class, after initialisation, a timer is used to run a main operating loop function over and over at a fixed interval (10hz by default). Our controller makes use of a finite state machine model to manage the control flow through the various states mentioned above. This fsm is shown in the diagram below. The Rectangular boxes (apart from the red ones) all depict States of this fsm. Each state requires a number of orange actions to completed or checks to pass before it can move onto the next state. The green states also include live checks for if the vehicle is armed and in the correct mode for offboard flight, as the vehicle will be in the air. The FSM also contains failure states for any of the checks where the vehicle which immediately go to Stop, and therefore immediately land and make safe in the air. The functionality of this state machine is encoded within the stateMachine(Time stamp) function, and is triggered by a Ros Timer running at 10hz ( this->execution_timer ). The States are defined in state.hpp . From an implementation standpoint, since the state machine has to run continuously, any called function cannot internally loop indefinitely and must execute and immediately exit. Traditionally FSMs switch states through the use of a large set of binary variables. In this particular application, this felt very verbose, and so we use boolean returning execution functions as our state machine checks. For example the Takeoff check calls to see whether this->smTakeoffVehicle(stamp) (main.cpp:246) returns true. case State::TAKEOFF: this->smOffboardArmed(stamp); if(!this->smTakeoffVehicle(stamp)) { RCLCPP_INFO(this->get_logger(), \"Waiting for Takeoff\"); } However looking at this function, it itself performs the takeoff procedure to a given height, always returning false, unless the vehicle is at its takeoff location.","title":"Controller Core Functionality"},{"location":"cpp_example_dev/#controller-communication-with-mavros","text":"Now we have the controller architecture in play, how does this controller actually talk to the vehicle! At the bottom of main.hpp you should see a whole bunch of Ros Publishers and Subscribers being declared (note how they are pointers). These pubs and subs are initialised within the class constructor/initialiser in main.cpp:67-97 . In order to detect arming and mode, we subscribe to mavros/state , and in order to get the local cartesian position and orientation of the vehicle, we also get mavros/local_position/pose . These both give us a constant stream of data which we save into variables this->vehicle_state and this->vehicle_local_position . In order to send position commands to the vehicle, we set up a publisher to mavros/setpoint_position/local and use the sendSetpointPositionPose(stamp, geometry_msgs::msg::PoseStamped) function to publish setpoints to the autopilot. The translated MAVLINK commands then tell the drone to go to that location and orienation immediately. Therefore in a number of places, we make use of interpolators to ensure that the vehicle can move from its location to any other at safe velocities and rates. Otherwise, the drone will ramp up to maximum velocity to go to far away locations which can be quite dangerous! That is why the CD3 interpolate library is included by default.","title":"Controller Communication with MAVROS"},{"location":"cpp_example_dev/#controller-user-implemented-functionality","text":"In creating this template, it was our intention to make the user developer experience as pleasant as possible. As previously mentioned we identified that the majority of drone functionality was mostly fixed between different applications, with only the application differing. In terms of our state machine, that corresponds to only executing application based at initialisation and during the execute state. We therefore decided to abstract this out into its own class of UserController within trajectory.hpp and trajectory.cpp . class UserController { public: UserController(UAVController *node); // Reset this controller void reset(); // User Controller Checking If The Start Location is Registered bool smReady(const rclcpp::Time& stamp); // User Controller Execute One Control Loop bool smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed); private: // ROS Helper Functions rclcpp::Logger get_logger(); rclcpp::Time now(); // The ROSnode itself UAVController* node; // User variables ... } The UserController only has 3 functions of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) which correspond with the parts of the State Machine which are important to the user. The other important variable is the node . This class is not a node in itself (A node cannot run another node). Therefore during initialisation, we pass in the main UAVController node so that we can call useful functions later. So how does UserController fit into the main node? UserController is actually declared in main.hpp:99 and initialised in main.cpp:100 . Doing a ctrl+f and searching for this->user_controller you can see the places where it gets called, and they are as described above. So then, where does the user code go! The code you write for your own applications therefore goes in two places: New functions and variables to do with your code are declared below the node variable in controller.hpp Implementations of these functions, as well as your implementations of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) should be provided into the gaps available in controller.cpp . Usefully for this example, we have already provided 80% of the implementation, including publishers and subscribers and the implmentation of all the core functions except smExecute(stamp, time_elapsed) which will be discussed below and left as an exercise for the reader. After the next section, have a read through controller.hpp and controller.cpp and try and follow the logic to see if it makes sense.","title":"Controller User Implemented Functionality"},{"location":"cpp_example_dev/#a-solution-to-the-scenario","text":"You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind. For the purpose of this tutorial, we have created this particular method of solving the problem, and other ways definitely exist! Unless you are confident in your ability, we ask that you follow for now :) We take the approach of characterising a vehicle's position solely based on its angle theta, with the following steps: Server sends how many drones are on the network every few seconds and labels drones from 0+ (Uses NotifyVehicles msg) Drones use id to work out starting location around the circle Wait for GO to Takeoff Wait for valid start location and GO to move to start locations Wait for GO to continue Vehicle flies around in a circle During flight, vehicle sends its own theta every second to server (Uses TargetAngle msg) Server responds with angle it should be at right now with respect to other vehicles (Uses TargetAngle msg) A simple brute force algorithm is to imagine each vehicle was correct and calculate ideal locations of all other vehicles. Then return the average of each ideal location for each drone. Drones then proportionally change velocity based on angle disparity. Usefully for you all, the tutorial already implements all of these functions except for part 5 and 6 which you will need to implement. Within controller.cpp your goal is to fill in steps 5 and 6 into the smExecute function. bool UserController::smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed) { // Get Time Elapsed Since State Change double time_elapsed_sec = time_elapsed.seconds(); // Current Vehicle Location geometry_msgs::msg::PoseStamped current_pos = this->node->vehicle_local_position; /* * * Implement Your Solution Here * */ // State Machine never exists by giving false. return false; } As you're developing, dont forget to run make often to compile and build your code! This will help you catch syntax errors and other bugs as your go. You may also want to try out some of the local testing instructions in the next tutorial and come back and implement other bits.","title":"A Solution to the Scenario"},{"location":"cpp_example_dev/#useful-tips-for-implementation","text":"Now we pride some guidelines and tips for implementing the solution yourself. Remember to have a look through the available variables. You can access these variables using the this->(myvariabe) functions.","title":"Useful Tips for Implementation"},{"location":"cpp_example_dev/#getting-the-actual-current-theta","text":"The algorithm requires sending the vehicles actual theta to the server for processing. The actual theta of the vehicle has to be calculated from the x,y location of the vehicle with respect to the origin location of the vehicle. Note: that many mathematics functions such as atan2(x,y) , sin(x) , cos(x) are available as is in these formats. View spoilers and code double current_theta = atan2(current_pos->pose.position.y - this->origin.y, current_pos->pose.position.x - this->origin.x);","title":"Getting the actual current theta"},{"location":"cpp_example_dev/#creating-and-publishing-messages","text":"The server uses the TargetAngle and NotifyVehicle messages to communicate with the vehicle. The vehicle then sends TargetAngle messages back to the server each execution step. Have a look at the TargetAngle msg inside your custom msgs folder. You can create a message in cpp using the following syntax: target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; ... Where the msg fields can be filled in by using the msg.<field> = ... notation. Once you have created the correct message for a particular publisher, you can publish the message by using: this->my_publisher->publish(msg); Have a look for which publisher you should be publishing with. View spoilers and code target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; msg.time = stamp; msg.theta = current_theta; this->notify_angle_pub->publish(msg);","title":"Creating and Publishing Messages"},{"location":"cpp_example_dev/#angular-velocity-and-position","text":"Now we've sent the actual theta information to the server, we should now calculate where the vehicle should go. We are doing this based on the time that has been elapsed and the vehicle velocity to calculate a setpoint based on where the vehicle should be right now. Therefore you will first need to calculate the angular velocity to see what angle the vehicle should be currently at. Secondly you can then find the actual theta by calculating the number of radians travelled in addition to the start location of the vehicle. You should set the calculated theta to the this->vehicle_setpoint_theta member variable. Note: You can use the fmod function to do a floating point modulo operation. View spoilers and code // Get Angular (Theta) Velocity double angular_vel = this->vehicle_velocity / circle_radius; // Amount of theta vehicle should have moved w.r.t to start location this->vehicle_setpoint_theta = fmod(this->vehicle_start_theta + time_elapsed_sec * angular_vel, 2*M_PI);","title":"Angular Velocity and Position"},{"location":"cpp_example_dev/#theta-to-position","text":"Now you have calculated the setpoint theta, we now need to work out the cartesian (x,y,z) coordinate for the drone to fly to using its internal position control. This can be done through trigonometry: $$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta)$$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta) But dont forget about \\(z\\) z and yaw too! View spoilers and code // Convert theta to coordinate location double x = this->circle_radius * cos(this->vehicle_setpoint_theta) + this->origin.x; double y = this->circle_radius * sin(this->vehicle_setpoint_theta) + this->origin.y; double z = this->height + this->origin.z; double yaw = this->vehicle_setpoint_theta;","title":"Theta to position"},{"location":"cpp_example_dev/#sending-vehicle-setpoint","text":"Finally with the position the vehicle should visit calculated, you can send off the Setpoint position for the vehicle to execute using the node's built in function. // Tell Vehicle to go to coordinate location this->node->sendSetpointPositionCoordinate(stamp, x, y, z, yaw); // Log this using the following function RCLCPP_INFO(this->get_logger(), \"Vehicle going to (%f, %f, %f), theta: %f\", x, y, z, yaw","title":"Sending Vehicle Setpoint"},{"location":"cpp_example_dev/#next-steps","text":"Congrats you have hopefully either begun or completed the implementation of a controller which should hopefully solve the example problem. You should now have a decent understanding of how the core UAV rosnode controller template is constructed. Have a look at the implementation for the offboard controller and see if you can match it's functionality with the algorithm steps shown above. See if you can identify how it connects with the controller you have just written. However now, we need to check its functionality - is it actually working or doing what we expect? We will cover how to perform local development and testing in the next chapter.","title":"Next Steps"},{"location":"creating/","text":"Creating your own Starling Project \u00b6 This tutorial takes you through using the Starling templates repository to generate your own custom starling application. Creating your own Starling Project Prerequists Project Structure Planning Generating the base Starling Project Adding Nodes to your project What is in the templates cpp_ros2_node_onboard_template python_ros2_node_offboard_template ros2_msgs_template Dockerfile Running your new project Initialising Git Next Steps Prerequists \u00b6 In order to complete this tutorial, you will need the following installed. You may have already installed these within Getting Strted The template generation uses the cookiecutter tool for generating custom projects from a template. Then run: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See cookiecutter installation for further details on different platforms. This will give you access to the cookiecutter command line interface. Recommendation is to sign up for Docker Hub and Github, necessary if you wish to fly your controller in the real world. Project Structure Planning \u00b6 Before diving in to creating your project, you first need to decide on the structure of the project. The structure is wholy determined by the application, and the functionality that is split between the central server and onboard each vehicle. Let's review our task for this tutorial: In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind. A Starling Project is comprised of one or more ROS Nodes which each encompass one piece of functionality. In this project we can identify the need for the following: A node onboard the vehicle which can arm, takeoff, land and fly it in a circle of radius r from a given start location in a safe manner. A node offboard on the cetral server which receives vehicle locations, finds the ideal locations and then sends that information back to the vehicles. Through this we identify that we may also need to provide a set of custom messages for the communication of specific information between server and vehicle. Therefore this Starling Project will contain the source code for an onboard node, an offboard node and a set of custom messages. An important task is then to name these beforehand as we will need to refer to these names in the next step. By default we have named them the following, but you should endeavour to name them something better! Offboard node: template_python_node Onboard node: template_cpp_node Custom msgs: template_msgs Generating the base Starling Project \u00b6 The first step is to build your own Starling project. The following will start the process of using the template to generate the base starling project. In your workspace, run the following command. cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory starling_template It will follow by asking you to fill in a number of details. The value in the square brackets indicates the default value if you choose not to enter anything. Press Enter to go on to the next one. The inputs include the following. Name Description Full Name Your name used for documentaiton Email Your email address used for documentation Short Description A short description of your project added to the documentation and project files Project Name The name you have given to this Starling Project, make sure that you are happy with this as changing the name after fact is a bit of a pain. Github Username Optionally your github username for filling in the README and metadata Docker Username Optionally your docker hub username which is used for naming the Starling image. Will be used to upload to if you wish to push it online. Docker Image Name The name of the Starling image that this repository produces Docker Image Name Full An autogenerated name based on your username and image name, you can leave as the default unless you really want to change it. By default it is <Docker Username>/<Docker Image Name> Onboard ROS2 Package Name The name of the onboard controller which this containers Dockerfile will run in onboard mode. Offboard ROS2 Package Name The name of the offboard controller which this containers Dockerfile will run in offboard mode. Note: The last two entries should correspond to the node names you came up with in the planning phase. Note: The last two entries are for automatically populating the run.sh script. The run.sh script is the default script your project's Docker container runs on startup. You can leave these two as defaults and edit the run.sh script later. Once complete, the project will be generated into a folder named by your project_name . For example, the default project with name starling_controller produces a project with the following structure: starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md We have the following folders and files. starling_controller will be populated by user created ros packages. Anything in this folder is directly copied to the Dockerfile and built. deployment contains a sample docker-compose file which runs a default simulation stack, and a sample kubernetes file for deployment, both will most definitely need to be edited. buildtools contains the specification that docker uses to build the container. It contains the naming for the docker image. Dockerfile contains the dockerfile which specifies the build steps for this project. It already specifies the installation of a number of dependencies, including libInterpolate interpolation library. Once generated, the Makefile can be used to build and run commands: cd <Your Application Name> # Go into the your new Starling application directory make # Will build the project make run # Will build and run the container make run_bash # Will build and run the container, putting you in a bash shell inside it. make help # Shows the help screen This should successfuly build your project container which you can try and run or inspect. Currently it has no funcionality so nothing can happen. Have a look inside the container using make run_bash . Note On windows you can either use WSL or have a look at some of the solutions in this link Adding Nodes to your project \u00b6 The generated project has no functionality right now. This repository contains other templates which will generate rosnodes for you. In particular cpp_ros2_node_onboard_template : Generates a ROS2 node, designed for running onboard the vehicle written in CPP. python_ros2_node_offboard_template : Generates a ROS2 node, designed for running offboard (central server) written in Python ros2_msgs_template : Generates a ROS2 msgs package which can be used by any ROS2 package within this container. These nodes can be added to your project using the following cookiecutter commands. Note that the packages should be generated into the starling_project_name directory of the base Starling project. Each of these commands are single line commands. # CPP Onboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory cpp_ros2_node_onboard_template -o starling_controller/starling_controller # Python Offboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory python_ros2_node_offboard_template -o starling_controller/starling_controller # Messages cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory ros2_msgs_template -o starling_controller/starling_controller Note the --directory option points cookiecutter to the correct template, the -o option specifies the output directory, in our case the output should be inside the created Starling project. Similar to the generating of the base project, these will ask a number of questions to you during the generation. In particular it will ask what the package_name is which will become the name of that particular node package. Name Default Description full_name starling_user Your name used for documentation email starling.user@starling.co.uk Your email address used for documentaiton year 2022 The year of creation for documentation package_name template_node The name of this ROS2 Node, make sure this is correct and then you note it down. It should match the ones given in the initial Starling setup short_description ROS2 node template A short description of the functionality of this node for documentation and project files custom_ros2_msgs_name template_msgs Important! The name of the custom msgs package name you have added as part of this starling project. The name must match exactly otherwise the default functionality will fail. Note convention for msg packages is to have a package name of format <mymessages>_msgs , e.g. circle_experiment_msgs . Note For those familiar with ROS1, it is ROS2 convention to keep messages in a seperate package to the ros nodes themselves. This should give you a file tree that looks something like the following (of course with your package names instead) starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- template_onboard_controller |-- ... |-- template_offboard_controller |-- ... |-- template_msgs |-- ... |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md That being said, the nodes can be run standalone for your own projects, one at a time, or whenever you need a new node within your project. Once these packages have been placed within the correct directory inside the Starling project, you can simply run make to check that they are successfully built. What is in the templates \u00b6 The set of node templates above should create you a project which runs the example scenario specifically developed for the purpose of this tutorial. This example has been designed to show the development of an onboard and an offboard container, as well as demonstratee communication between the two. The scenario is as follows: We have \\(n\\) n drones which we would like to fly equidistant around a circle of fixed radius at a initial velocity. A central server will send each drone an id \\(i<n\\) i<n to determine its start location around the circle. Once received the drones will start flying around the circle and send its current position to the server. The server collates the drones informations to determine if any of the drones are lagging or ahead of where they should be. This ideal position is sent back to each drone. The drone adjusts its velocity to try based on the error to match with the ideal. With this in mind we can quickly run through what is in each of the ros node templates. Note: More detail about the actual functionality within these nodes will be in this tutorial section cpp_ros2_node_onboard_template \u00b6 |-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp This node runs onboard the vehicle and interfaces with MAVROS. It contains a state machine with functionality to arm, takeoff, land, loiter and takes care of safety functionality. CMakeLists.txt : contains the instructions to build this rosnode. This includes specifying dependencies and extra libraries (e.g. messages such as geometry_msgs or external dependencies). It also specifies the name of the binary containing all of your functionality. By default this is controller . include and src : In CPP, your code files are split into header files (specifying object definitions) and source files (specifying object functionality), these are stored here launch : contains a ROS launch file. We use XML notation to describe how your rosnode gets launched, including extra parameters or other changes you want to make at runtime instead of buildtime. This is what gets run to run your rosnode package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. As a brief overview of the code files: main.hpp and main.cpp : Contains the program entrypoint function and the core of the ros node. It contains all of the core functionality to fly a vehicle as well as the state machine. It includes the user controller specified in controller.hpp to be expected to run during the execution phase of the state machine. controller.hpp and controller.cpp : For the majority of simple applications, a user should only need to provide their own version of these files. The controller contains an initialisation and loop function which a user can fill in. state.hpp : A header only file containing the states of the state machine. python_ros2_node_offboard_template \u00b6 |-- package.xml |-- resource | `-- template_python_node |-- setup.cfg |-- setup.py |-- template_python_node | |-- __init__.py | `-- main.py `-- test |-- test_copyright.py |-- test_flake8.py `-- test_pep257.py This node runs offboard on the central server. It is designed to run on its own with no external dependence on anything outside of the application. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. resource : A python ros package special folder, no need to touch setup.cfg : Configuration file specifying where key resources are setup.py : The python equivalent of CMakeLists.txt and contains the instructions to build this rosnode. It specifies which resources are copied over and available to the rosnode at runtime. Also specifies the name of the binary, and which function it is intended to run. By default this is controller <your rosnode name> e.g. template_python_node : The source directory for your python files. test : A number of testing utilities which can be run with pytest. Currently not used. As a brief overview of code files: main.py : Contains a ros node which uses a timer to repeat poll the current state of vehicles on the network at given intervals. It then performs the calculation of ideal vehicle location and sends that to the vehicles. ros2_msgs_template \u00b6 |-- CMakeLists.txt |-- msg | |-- NotifyVehicles.msg | `-- TargetAngle.msg `-- package.xml This node is purely for specifying and building the custom ros messages in our application. Any application which uses these messages need a compiled version of this node. CMakeLists.txt : contains the instructions to build the messages. Any extra messages or services need to be added to the CMakeLists. msg : A list of specified custom messages. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. Dockerfile \u00b6 As mentioned in the previous tutorial , a Dockerfile is used as a recipe to build your controller docker container. The Dockerfile in this template contains the command line instructions to build your controller. By default it will install a number of useful libraries for compatibility. If you need any new libraries, you will have to add their installation here It then essentially copies in all of the rosnodes specified within the project name directory and runs them through the standard ROS2 build tool named colcon . It also copies over the run.sh file which the Dockerfile will run on container startup. Therefore the run.sh should have the instructions for running your applications. Thankfully you do not need to run docker build automatically as we have setup a special build system which is wrapped up inside the Makefile . Running your new project \u00b6 With your project now constructed, you can now re-run your container with the same make commands as earlier. cd <Your Application Name> # Go into the your new Starling application directory make run # Will build and run the container This will build a container called <Docker Username>/<Docker Image Name> with tag latest e.g. myname/starling_template:latest This will build start the onboard controller by default, but it will start complaining that it hasn't received any state or position messages for initialisation. This is normal for now! If you want to start the offboard controller, you can add the extra option ENV=\"-e OFFBOARD=true\" to the make command like so make run ENV=\"-e OFFBOARD=true\" . Where it will start trying to identify the number of vehicles on the network, but of course it cannot find any! You can have a look inside both container using make run_bash . Initialising Git \u00b6 Optionally, at this point you can start version controller on your project in order to save your progress. To initalise git and create your first commit, go to the root of your project and run: git init git add -A git commit -m \"Initial Commit\" If you want to push this code onto github, you can follow this tutorial . In short, create an empty github repository of the same name in your github account, then change the remote locally: git remote add origin <remote repository URL> git remote -v git push origin master Next Steps \u00b6 Congratulations, you now have your own Starling application! It doesn't quite have any functionality just yet but before we get to adding some, it's important to understand how you run the simulation for you to test your controller against!","title":"4. Creating your own Starling project"},{"location":"creating/#creating-your-own-starling-project","text":"This tutorial takes you through using the Starling templates repository to generate your own custom starling application. Creating your own Starling Project Prerequists Project Structure Planning Generating the base Starling Project Adding Nodes to your project What is in the templates cpp_ros2_node_onboard_template python_ros2_node_offboard_template ros2_msgs_template Dockerfile Running your new project Initialising Git Next Steps","title":"Creating your own Starling Project"},{"location":"creating/#prerequists","text":"In order to complete this tutorial, you will need the following installed. You may have already installed these within Getting Strted The template generation uses the cookiecutter tool for generating custom projects from a template. Then run: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See cookiecutter installation for further details on different platforms. This will give you access to the cookiecutter command line interface. Recommendation is to sign up for Docker Hub and Github, necessary if you wish to fly your controller in the real world.","title":"Prerequists"},{"location":"creating/#project-structure-planning","text":"Before diving in to creating your project, you first need to decide on the structure of the project. The structure is wholy determined by the application, and the functionality that is split between the central server and onboard each vehicle. Let's review our task for this tutorial: In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind. A Starling Project is comprised of one or more ROS Nodes which each encompass one piece of functionality. In this project we can identify the need for the following: A node onboard the vehicle which can arm, takeoff, land and fly it in a circle of radius r from a given start location in a safe manner. A node offboard on the cetral server which receives vehicle locations, finds the ideal locations and then sends that information back to the vehicles. Through this we identify that we may also need to provide a set of custom messages for the communication of specific information between server and vehicle. Therefore this Starling Project will contain the source code for an onboard node, an offboard node and a set of custom messages. An important task is then to name these beforehand as we will need to refer to these names in the next step. By default we have named them the following, but you should endeavour to name them something better! Offboard node: template_python_node Onboard node: template_cpp_node Custom msgs: template_msgs","title":"Project Structure Planning"},{"location":"creating/#generating-the-base-starling-project","text":"The first step is to build your own Starling project. The following will start the process of using the template to generate the base starling project. In your workspace, run the following command. cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory starling_template It will follow by asking you to fill in a number of details. The value in the square brackets indicates the default value if you choose not to enter anything. Press Enter to go on to the next one. The inputs include the following. Name Description Full Name Your name used for documentaiton Email Your email address used for documentation Short Description A short description of your project added to the documentation and project files Project Name The name you have given to this Starling Project, make sure that you are happy with this as changing the name after fact is a bit of a pain. Github Username Optionally your github username for filling in the README and metadata Docker Username Optionally your docker hub username which is used for naming the Starling image. Will be used to upload to if you wish to push it online. Docker Image Name The name of the Starling image that this repository produces Docker Image Name Full An autogenerated name based on your username and image name, you can leave as the default unless you really want to change it. By default it is <Docker Username>/<Docker Image Name> Onboard ROS2 Package Name The name of the onboard controller which this containers Dockerfile will run in onboard mode. Offboard ROS2 Package Name The name of the offboard controller which this containers Dockerfile will run in offboard mode. Note: The last two entries should correspond to the node names you came up with in the planning phase. Note: The last two entries are for automatically populating the run.sh script. The run.sh script is the default script your project's Docker container runs on startup. You can leave these two as defaults and edit the run.sh script later. Once complete, the project will be generated into a folder named by your project_name . For example, the default project with name starling_controller produces a project with the following structure: starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md We have the following folders and files. starling_controller will be populated by user created ros packages. Anything in this folder is directly copied to the Dockerfile and built. deployment contains a sample docker-compose file which runs a default simulation stack, and a sample kubernetes file for deployment, both will most definitely need to be edited. buildtools contains the specification that docker uses to build the container. It contains the naming for the docker image. Dockerfile contains the dockerfile which specifies the build steps for this project. It already specifies the installation of a number of dependencies, including libInterpolate interpolation library. Once generated, the Makefile can be used to build and run commands: cd <Your Application Name> # Go into the your new Starling application directory make # Will build the project make run # Will build and run the container make run_bash # Will build and run the container, putting you in a bash shell inside it. make help # Shows the help screen This should successfuly build your project container which you can try and run or inspect. Currently it has no funcionality so nothing can happen. Have a look inside the container using make run_bash . Note On windows you can either use WSL or have a look at some of the solutions in this link","title":"Generating the base Starling Project"},{"location":"creating/#adding-nodes-to-your-project","text":"The generated project has no functionality right now. This repository contains other templates which will generate rosnodes for you. In particular cpp_ros2_node_onboard_template : Generates a ROS2 node, designed for running onboard the vehicle written in CPP. python_ros2_node_offboard_template : Generates a ROS2 node, designed for running offboard (central server) written in Python ros2_msgs_template : Generates a ROS2 msgs package which can be used by any ROS2 package within this container. These nodes can be added to your project using the following cookiecutter commands. Note that the packages should be generated into the starling_project_name directory of the base Starling project. Each of these commands are single line commands. # CPP Onboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory cpp_ros2_node_onboard_template -o starling_controller/starling_controller # Python Offboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory python_ros2_node_offboard_template -o starling_controller/starling_controller # Messages cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory ros2_msgs_template -o starling_controller/starling_controller Note the --directory option points cookiecutter to the correct template, the -o option specifies the output directory, in our case the output should be inside the created Starling project. Similar to the generating of the base project, these will ask a number of questions to you during the generation. In particular it will ask what the package_name is which will become the name of that particular node package. Name Default Description full_name starling_user Your name used for documentation email starling.user@starling.co.uk Your email address used for documentaiton year 2022 The year of creation for documentation package_name template_node The name of this ROS2 Node, make sure this is correct and then you note it down. It should match the ones given in the initial Starling setup short_description ROS2 node template A short description of the functionality of this node for documentation and project files custom_ros2_msgs_name template_msgs Important! The name of the custom msgs package name you have added as part of this starling project. The name must match exactly otherwise the default functionality will fail. Note convention for msg packages is to have a package name of format <mymessages>_msgs , e.g. circle_experiment_msgs . Note For those familiar with ROS1, it is ROS2 convention to keep messages in a seperate package to the ros nodes themselves. This should give you a file tree that looks something like the following (of course with your package names instead) starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- template_onboard_controller |-- ... |-- template_offboard_controller |-- ... |-- template_msgs |-- ... |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md That being said, the nodes can be run standalone for your own projects, one at a time, or whenever you need a new node within your project. Once these packages have been placed within the correct directory inside the Starling project, you can simply run make to check that they are successfully built.","title":"Adding Nodes to your project"},{"location":"creating/#what-is-in-the-templates","text":"The set of node templates above should create you a project which runs the example scenario specifically developed for the purpose of this tutorial. This example has been designed to show the development of an onboard and an offboard container, as well as demonstratee communication between the two. The scenario is as follows: We have \\(n\\) n drones which we would like to fly equidistant around a circle of fixed radius at a initial velocity. A central server will send each drone an id \\(i<n\\) i<n to determine its start location around the circle. Once received the drones will start flying around the circle and send its current position to the server. The server collates the drones informations to determine if any of the drones are lagging or ahead of where they should be. This ideal position is sent back to each drone. The drone adjusts its velocity to try based on the error to match with the ideal. With this in mind we can quickly run through what is in each of the ros node templates. Note: More detail about the actual functionality within these nodes will be in this tutorial section","title":"What is in the templates"},{"location":"creating/#cpp_ros2_node_onboard_template","text":"|-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp This node runs onboard the vehicle and interfaces with MAVROS. It contains a state machine with functionality to arm, takeoff, land, loiter and takes care of safety functionality. CMakeLists.txt : contains the instructions to build this rosnode. This includes specifying dependencies and extra libraries (e.g. messages such as geometry_msgs or external dependencies). It also specifies the name of the binary containing all of your functionality. By default this is controller . include and src : In CPP, your code files are split into header files (specifying object definitions) and source files (specifying object functionality), these are stored here launch : contains a ROS launch file. We use XML notation to describe how your rosnode gets launched, including extra parameters or other changes you want to make at runtime instead of buildtime. This is what gets run to run your rosnode package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. As a brief overview of the code files: main.hpp and main.cpp : Contains the program entrypoint function and the core of the ros node. It contains all of the core functionality to fly a vehicle as well as the state machine. It includes the user controller specified in controller.hpp to be expected to run during the execution phase of the state machine. controller.hpp and controller.cpp : For the majority of simple applications, a user should only need to provide their own version of these files. The controller contains an initialisation and loop function which a user can fill in. state.hpp : A header only file containing the states of the state machine.","title":"cpp_ros2_node_onboard_template"},{"location":"creating/#python_ros2_node_offboard_template","text":"|-- package.xml |-- resource | `-- template_python_node |-- setup.cfg |-- setup.py |-- template_python_node | |-- __init__.py | `-- main.py `-- test |-- test_copyright.py |-- test_flake8.py `-- test_pep257.py This node runs offboard on the central server. It is designed to run on its own with no external dependence on anything outside of the application. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. resource : A python ros package special folder, no need to touch setup.cfg : Configuration file specifying where key resources are setup.py : The python equivalent of CMakeLists.txt and contains the instructions to build this rosnode. It specifies which resources are copied over and available to the rosnode at runtime. Also specifies the name of the binary, and which function it is intended to run. By default this is controller <your rosnode name> e.g. template_python_node : The source directory for your python files. test : A number of testing utilities which can be run with pytest. Currently not used. As a brief overview of code files: main.py : Contains a ros node which uses a timer to repeat poll the current state of vehicles on the network at given intervals. It then performs the calculation of ideal vehicle location and sends that to the vehicles.","title":"python_ros2_node_offboard_template"},{"location":"creating/#ros2_msgs_template","text":"|-- CMakeLists.txt |-- msg | |-- NotifyVehicles.msg | `-- TargetAngle.msg `-- package.xml This node is purely for specifying and building the custom ros messages in our application. Any application which uses these messages need a compiled version of this node. CMakeLists.txt : contains the instructions to build the messages. Any extra messages or services need to be added to the CMakeLists. msg : A list of specified custom messages. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project.","title":"ros2_msgs_template"},{"location":"creating/#dockerfile","text":"As mentioned in the previous tutorial , a Dockerfile is used as a recipe to build your controller docker container. The Dockerfile in this template contains the command line instructions to build your controller. By default it will install a number of useful libraries for compatibility. If you need any new libraries, you will have to add their installation here It then essentially copies in all of the rosnodes specified within the project name directory and runs them through the standard ROS2 build tool named colcon . It also copies over the run.sh file which the Dockerfile will run on container startup. Therefore the run.sh should have the instructions for running your applications. Thankfully you do not need to run docker build automatically as we have setup a special build system which is wrapped up inside the Makefile .","title":"Dockerfile"},{"location":"creating/#running-your-new-project","text":"With your project now constructed, you can now re-run your container with the same make commands as earlier. cd <Your Application Name> # Go into the your new Starling application directory make run # Will build and run the container This will build a container called <Docker Username>/<Docker Image Name> with tag latest e.g. myname/starling_template:latest This will build start the onboard controller by default, but it will start complaining that it hasn't received any state or position messages for initialisation. This is normal for now! If you want to start the offboard controller, you can add the extra option ENV=\"-e OFFBOARD=true\" to the make command like so make run ENV=\"-e OFFBOARD=true\" . Where it will start trying to identify the number of vehicles on the network, but of course it cannot find any! You can have a look inside both container using make run_bash .","title":"Running your new project"},{"location":"creating/#initialising-git","text":"Optionally, at this point you can start version controller on your project in order to save your progress. To initalise git and create your first commit, go to the root of your project and run: git init git add -A git commit -m \"Initial Commit\" If you want to push this code onto github, you can follow this tutorial . In short, create an empty github repository of the same name in your github account, then change the remote locally: git remote add origin <remote repository URL> git remote -v git push origin master","title":"Initialising Git"},{"location":"creating/#next-steps","text":"Congratulations, you now have your own Starling application! It doesn't quite have any functionality just yet but before we get to adding some, it's important to understand how you run the simulation for you to test your controller against!","title":"Next Steps"},{"location":"docker/","text":"Docker and Containerisation \u00b6 This tutorial gives a brief introduction to a key element of Starling - containerisation. By the end you will hopefully have an idea of what containerisation is, what docker is, how to use it, and how we use it within Starling. This is adapted from the Duckietown Docker Docs , Docker Docs tutorial , and a number of other resources. Docker and Containerisation Introduction What is Containerisation and Docker Docker Concepts in more detail Starling Container Ecosystem Using Docker with Starling Getting and Running Containers Creating Containers Layer Caching Inspecting a container Starling Mavros Next Steps Introduction \u00b6 What is Containerisation and Docker \u00b6 It would be nice to give a computer - any computer with an internet connection - a short string of ASCII characters (say via a keyboard), press enter, and return to see some program running. Forget about where the program was built or what software you happened to be running at the time (this can be checked, and we can fetch the necessary dependencies). Sounds simple, right? In fact, this is an engineering task that has taken thousands of the world\u2019s brightest developers many decades to implement. Thanks to the magic of container technology we now can run any Linux program on almost any networked device on the planet, as is. All of the environment preparation, installation and configuration steps can be automated from start to finish. Depending on how much network bandwidth you have, it might take a while, but that\u2019s all right. All you need to do is type the string correctly. Docker is one very widely used example of containerisation technology, and the one we make use of in Starling. They provide a large number of tools and programs to help us contain, develop, test and deploy our containers to the real world. If you followed the getting started , you should hopefully have done the full docker install. If not, you can run the following command from a linux command line to install basic docker. curl -sSL https://get.docker.com/ | sh Docker Concepts in more detail \u00b6 Adapted from Docker Resources A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. Container images become containers at runtime and in the case of Docker containers \u2013 images become containers when they run on Docker Engine. Available for both Linux and Windows-based applications, containerized software will always run the same, regardless of the infrastructure. Containers isolate software from its environment and ensure that it works uniformly despite differences for instance between development and staging. Containers are Standard (can run anywhere), Lightweight (Share low level machine system and not the whole Operating System) and Secure (Each application is as isolated as possible). For us this also translates to providing Reproduceable and Reusable systems. On the left, Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. Containers take up less space than VMs (container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems. On the right, Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries and libraries \u2013 taking up tens of GBs. VMs can also be slow to boot. Starling Container Ecosystem \u00b6 The purpose of Starling is to allow you to quickly and easily install and run a UAV simulation within a simulated environment, so that you can test your developed controllers against a semi-realistic scenario, to then test in the real world Therefore Starling is a set of pre-built programs/executables, some of which are pre-configured for the following: Running a Physics Simulation with Visualisation Running the Drone autopilot control software locally (a.k.a Software In The Loop or SITL) Running the interface between Mavlink and other protocols such as the Robot Operating System (ROS) And many others... These pre-built containers are all available in the StarlingUAS repository on github and on Docker Hub. Together these containers form a modular ecosystem of drone systems which can be composed together to develop software for real drones. Any controllers developed via the simulator can be directly ported to run on a real drone. Using Docker with Starling \u00b6 Getting and Running Containers \u00b6 Every docker container is registered to a developer or organisation. In Starling, our docker organisation is known as uobflightlabstarling . Within our organisation, we have a large number of Docker containers available. These Docker containers live inside container registries (such as DockerHub), which are servers that host Docker images. A Docker image is one particular version or snapshot of a container and is basically a filesystem snapshot - a single file that contains everything you need to run our container. You can manually fetch one of our core containers called starling-mavros from docker hub using: docker pull uobflightlabstarling/starling-mavros You can also try and pull one of our simulation containers: docker pull uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This might take a few minutes to download depending on internet connection (some containers like the simulation can be quite big!). Once downloaded, to see a list of Docker images on your machine, run: docker images Every image has an image ID, a name and a tag REPOSITORY TAG IMAGE ID CREATED SIZE uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB To run a Docker container, type the repository name, like so: docker run uobflightlabstarling/starling-mavros # Or with the tag if you want to run a specific tag (version) of that container docker run uobflightlabstarling/starling-mavros:latest In another terminal, you can see what is currently running using: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4fd1e0948f23 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 46 seconds ago Up 45 seconds vigilant_nobel Note how your the running container has a container ID , a base image you ran, and at the end, a funny name vigilant_noble . This funny name is an alias for the container ID. To stop the container, simply press ctrl+c in the terminal which you ran docker run . As a second example, you can similarly try and run the simulator, this time also specifying a port mapping to let you see the simulator in your web-browser. docker run -p 8080:8080 uobflightlabstarling/starling-sim-iris-px4-flightarena Then you can navigate to localhost:8080 in your web browser to see the simulator. You should hopefully see something like the following: You can use the cursor to move around the environment, we will be coming back to the simulator in a later section . To stop the simulator, you can try and use ctrl+c , but sometimes this doenst work. Another way is to first get the container ID or name like before: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6a4bd538118c uobflightlabstarling/starling-sim-iris-px4-flightarena \"/entrypoint.sh ros2\u2026\" 2 minutes ago Up 2 minutes 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp trusting_diffie See how the name is trusting_diffie with ID 6a4bd538118c . You can then explicitly stop the container by running (it can sometimes take a minute). docker stop trusting_diffie # or docker stop 6a4bd538118c Dont forget to also remove the container afterwards docker rm trusting_diffie # or docker rm 6a4bd538118c Creating Containers \u00b6 To create a Docker image we write a recipe, called a Dockerfile . A Dockerfile is a text file that specifies the commands required to create a Docker image, typically by modifying an existing container image using a scripting interface. They also have special keywords (which are always CAPITALIZED), like FROM , RUN , ENTRYPOINT and so on. For example, create a file called Dockerfile with the following content: FROM ros:foxy # Defines the base image RUN touch new_file1 # new_file1 will be part of our snapshot CMD ls -l # Default command to be run when the container is started Now, to build the image we can simply run: docker build -t your/duck:v3 . # Where '.' is the directory containing your Dockerfile You should see something like: Sending build context to Docker daemon 2.048kB Step 1/3 : FROM uobflightlabstarling/starling-mavros --- ea2f90g8de9e Step 2/3 : RUN touch new_file1 --- e3b75gt9zyc4 Step 3/3 : CMD ls -l --- Running in 14f834yud59 Removing intermediate container 14f834yud59 --- 05a3bd381fc2 Successfully built 05a3bd381fc2 Successfully tagged your/duck:v3 Now run the command docker images in your terminal, and you should see an image called your/duck with tag v3: docker images REPOSITORY TAG IMAGE ID CREATED SIZE your/duck v3 ea2f90g8de9e 1 minute ago 2.06GB uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB This procedure is identical to the snapshot method we performed earlier, but the result is much cleaner. Now, instead of needing to carry around a 2.06GB BLOB, we can just store the 4KB text file and rest assured that all our important setup commands are contained within. Similar to before, we can simply run: docker run -it your/duck:v3 total 0 -rw-r--r-- 1 root root 0 May 21 21:35 new_file1 Notice that as soon as we run the container, Docker will execute the ls -l command as specified by the Dockerfile, revealing new_file1 was stored in the image. However we can still override ls -l by passing a command line argument: docker run -it your/duck:v3 [custom command] In the next tutorial, we will go into more detail in how these Dockerfiles are constructed for us. Layer Caching \u00b6 An important concept in Docker is the layers . In the previous section you may think that every time we build, we end up having to copy over the entire parent container. e.g. your/duck:v3 takes up another 2Gb of storage space! In actual fact, it (thankfully) does not, because under the hood the executable does not exist as one giant individible binary. It is in fact split into multiple independnet layers which can be shared in between images! Essentially each RUN line in your Dockerfile is compiled into a new layer placed upon the previous layers. This is helpful as if you try to build your container again, unless you change something, those previous layers are cached by Docker to be used instead of rebuilding the entire thing from scratch! Inspecting a container \u00b6 One of the downsides of containers is that manipulating files and inspecting the their state is not as simple. Previously, you could just browser through your own file system and check things. Now that a container has its own file system, its not as clear how you could check things have been set up correctly, or test run commands manually or similar. There are a number of different ways, but the simplest way is to exec into a running container. As an example, you can run starling-mavros again in one terminal. docker run uobflightlabstarling/starling-mavros In another terminal, identify the container ID or name by using docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 81b7dfb6c443 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 3 seconds ago Up 2 seconds angry_yalow Note: The IDs have changed from the previous time we ran this container. Sometimes you want containers to persist, or do not want to delete them for testing and such. We can then use the ID of 81b7dfb6c443 or its name angry_yalow to exec into a container to run a command: docker exec -it angry_yalow [command] For example, in most cases it will be most useful to open up a bash terminal to inspect contents: docker exec -it angry_yalow bash root@81b7dfb6c443:/ros_ws# This opens up a terminal inside the container for you to navigate around and inspect things as you wish, in a similar manner to if you SSH'd into another machine. Note: Use the cat command to view the contents of files. Note: These containers have almost no tools to keep them slim. If you want to edit things, you will need to download a command line file editor. Run apt-get update then install an editor like nano with apt-get install nano . Starling Mavros \u00b6 Finally, we bring in ros2 and uav control from the previous tutorial . In Starling, there exists a core container called starling-mavros which facilitates the communication between the user application and the UAV autopilot in simulation or reality. This container, which you have hopefully run above, uses a Mavros node is to translate between ROS2 for the user, and MAVLINK for the autopilot. We give examples of its use later on. Next Steps \u00b6 Hopefully you now have a decent understanding of what containerisation is and its purpose within Starling. You have also had a go at using the Docker command line tool to pull, run, build and inspect Starling containers going forward. With all that, we are now at a point where you can start creating your own containers to use!","title":"3. Docker and Containerisation"},{"location":"docker/#docker-and-containerisation","text":"This tutorial gives a brief introduction to a key element of Starling - containerisation. By the end you will hopefully have an idea of what containerisation is, what docker is, how to use it, and how we use it within Starling. This is adapted from the Duckietown Docker Docs , Docker Docs tutorial , and a number of other resources. Docker and Containerisation Introduction What is Containerisation and Docker Docker Concepts in more detail Starling Container Ecosystem Using Docker with Starling Getting and Running Containers Creating Containers Layer Caching Inspecting a container Starling Mavros Next Steps","title":"Docker and Containerisation"},{"location":"docker/#introduction","text":"","title":"Introduction"},{"location":"docker/#what-is-containerisation-and-docker","text":"It would be nice to give a computer - any computer with an internet connection - a short string of ASCII characters (say via a keyboard), press enter, and return to see some program running. Forget about where the program was built or what software you happened to be running at the time (this can be checked, and we can fetch the necessary dependencies). Sounds simple, right? In fact, this is an engineering task that has taken thousands of the world\u2019s brightest developers many decades to implement. Thanks to the magic of container technology we now can run any Linux program on almost any networked device on the planet, as is. All of the environment preparation, installation and configuration steps can be automated from start to finish. Depending on how much network bandwidth you have, it might take a while, but that\u2019s all right. All you need to do is type the string correctly. Docker is one very widely used example of containerisation technology, and the one we make use of in Starling. They provide a large number of tools and programs to help us contain, develop, test and deploy our containers to the real world. If you followed the getting started , you should hopefully have done the full docker install. If not, you can run the following command from a linux command line to install basic docker. curl -sSL https://get.docker.com/ | sh","title":"What is Containerisation and Docker"},{"location":"docker/#docker-concepts-in-more-detail","text":"Adapted from Docker Resources A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. Container images become containers at runtime and in the case of Docker containers \u2013 images become containers when they run on Docker Engine. Available for both Linux and Windows-based applications, containerized software will always run the same, regardless of the infrastructure. Containers isolate software from its environment and ensure that it works uniformly despite differences for instance between development and staging. Containers are Standard (can run anywhere), Lightweight (Share low level machine system and not the whole Operating System) and Secure (Each application is as isolated as possible). For us this also translates to providing Reproduceable and Reusable systems. On the left, Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. Containers take up less space than VMs (container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems. On the right, Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries and libraries \u2013 taking up tens of GBs. VMs can also be slow to boot.","title":"Docker Concepts in more detail"},{"location":"docker/#starling-container-ecosystem","text":"The purpose of Starling is to allow you to quickly and easily install and run a UAV simulation within a simulated environment, so that you can test your developed controllers against a semi-realistic scenario, to then test in the real world Therefore Starling is a set of pre-built programs/executables, some of which are pre-configured for the following: Running a Physics Simulation with Visualisation Running the Drone autopilot control software locally (a.k.a Software In The Loop or SITL) Running the interface between Mavlink and other protocols such as the Robot Operating System (ROS) And many others... These pre-built containers are all available in the StarlingUAS repository on github and on Docker Hub. Together these containers form a modular ecosystem of drone systems which can be composed together to develop software for real drones. Any controllers developed via the simulator can be directly ported to run on a real drone.","title":"Starling Container Ecosystem"},{"location":"docker/#using-docker-with-starling","text":"","title":"Using Docker with Starling"},{"location":"docker/#getting-and-running-containers","text":"Every docker container is registered to a developer or organisation. In Starling, our docker organisation is known as uobflightlabstarling . Within our organisation, we have a large number of Docker containers available. These Docker containers live inside container registries (such as DockerHub), which are servers that host Docker images. A Docker image is one particular version or snapshot of a container and is basically a filesystem snapshot - a single file that contains everything you need to run our container. You can manually fetch one of our core containers called starling-mavros from docker hub using: docker pull uobflightlabstarling/starling-mavros You can also try and pull one of our simulation containers: docker pull uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This might take a few minutes to download depending on internet connection (some containers like the simulation can be quite big!). Once downloaded, to see a list of Docker images on your machine, run: docker images Every image has an image ID, a name and a tag REPOSITORY TAG IMAGE ID CREATED SIZE uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB To run a Docker container, type the repository name, like so: docker run uobflightlabstarling/starling-mavros # Or with the tag if you want to run a specific tag (version) of that container docker run uobflightlabstarling/starling-mavros:latest In another terminal, you can see what is currently running using: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4fd1e0948f23 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 46 seconds ago Up 45 seconds vigilant_nobel Note how your the running container has a container ID , a base image you ran, and at the end, a funny name vigilant_noble . This funny name is an alias for the container ID. To stop the container, simply press ctrl+c in the terminal which you ran docker run . As a second example, you can similarly try and run the simulator, this time also specifying a port mapping to let you see the simulator in your web-browser. docker run -p 8080:8080 uobflightlabstarling/starling-sim-iris-px4-flightarena Then you can navigate to localhost:8080 in your web browser to see the simulator. You should hopefully see something like the following: You can use the cursor to move around the environment, we will be coming back to the simulator in a later section . To stop the simulator, you can try and use ctrl+c , but sometimes this doenst work. Another way is to first get the container ID or name like before: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6a4bd538118c uobflightlabstarling/starling-sim-iris-px4-flightarena \"/entrypoint.sh ros2\u2026\" 2 minutes ago Up 2 minutes 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp trusting_diffie See how the name is trusting_diffie with ID 6a4bd538118c . You can then explicitly stop the container by running (it can sometimes take a minute). docker stop trusting_diffie # or docker stop 6a4bd538118c Dont forget to also remove the container afterwards docker rm trusting_diffie # or docker rm 6a4bd538118c","title":"Getting and Running Containers"},{"location":"docker/#creating-containers","text":"To create a Docker image we write a recipe, called a Dockerfile . A Dockerfile is a text file that specifies the commands required to create a Docker image, typically by modifying an existing container image using a scripting interface. They also have special keywords (which are always CAPITALIZED), like FROM , RUN , ENTRYPOINT and so on. For example, create a file called Dockerfile with the following content: FROM ros:foxy # Defines the base image RUN touch new_file1 # new_file1 will be part of our snapshot CMD ls -l # Default command to be run when the container is started Now, to build the image we can simply run: docker build -t your/duck:v3 . # Where '.' is the directory containing your Dockerfile You should see something like: Sending build context to Docker daemon 2.048kB Step 1/3 : FROM uobflightlabstarling/starling-mavros --- ea2f90g8de9e Step 2/3 : RUN touch new_file1 --- e3b75gt9zyc4 Step 3/3 : CMD ls -l --- Running in 14f834yud59 Removing intermediate container 14f834yud59 --- 05a3bd381fc2 Successfully built 05a3bd381fc2 Successfully tagged your/duck:v3 Now run the command docker images in your terminal, and you should see an image called your/duck with tag v3: docker images REPOSITORY TAG IMAGE ID CREATED SIZE your/duck v3 ea2f90g8de9e 1 minute ago 2.06GB uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB This procedure is identical to the snapshot method we performed earlier, but the result is much cleaner. Now, instead of needing to carry around a 2.06GB BLOB, we can just store the 4KB text file and rest assured that all our important setup commands are contained within. Similar to before, we can simply run: docker run -it your/duck:v3 total 0 -rw-r--r-- 1 root root 0 May 21 21:35 new_file1 Notice that as soon as we run the container, Docker will execute the ls -l command as specified by the Dockerfile, revealing new_file1 was stored in the image. However we can still override ls -l by passing a command line argument: docker run -it your/duck:v3 [custom command] In the next tutorial, we will go into more detail in how these Dockerfiles are constructed for us.","title":"Creating Containers"},{"location":"docker/#layer-caching","text":"An important concept in Docker is the layers . In the previous section you may think that every time we build, we end up having to copy over the entire parent container. e.g. your/duck:v3 takes up another 2Gb of storage space! In actual fact, it (thankfully) does not, because under the hood the executable does not exist as one giant individible binary. It is in fact split into multiple independnet layers which can be shared in between images! Essentially each RUN line in your Dockerfile is compiled into a new layer placed upon the previous layers. This is helpful as if you try to build your container again, unless you change something, those previous layers are cached by Docker to be used instead of rebuilding the entire thing from scratch!","title":"Layer Caching"},{"location":"docker/#inspecting-a-container","text":"One of the downsides of containers is that manipulating files and inspecting the their state is not as simple. Previously, you could just browser through your own file system and check things. Now that a container has its own file system, its not as clear how you could check things have been set up correctly, or test run commands manually or similar. There are a number of different ways, but the simplest way is to exec into a running container. As an example, you can run starling-mavros again in one terminal. docker run uobflightlabstarling/starling-mavros In another terminal, identify the container ID or name by using docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 81b7dfb6c443 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 3 seconds ago Up 2 seconds angry_yalow Note: The IDs have changed from the previous time we ran this container. Sometimes you want containers to persist, or do not want to delete them for testing and such. We can then use the ID of 81b7dfb6c443 or its name angry_yalow to exec into a container to run a command: docker exec -it angry_yalow [command] For example, in most cases it will be most useful to open up a bash terminal to inspect contents: docker exec -it angry_yalow bash root@81b7dfb6c443:/ros_ws# This opens up a terminal inside the container for you to navigate around and inspect things as you wish, in a similar manner to if you SSH'd into another machine. Note: Use the cat command to view the contents of files. Note: These containers have almost no tools to keep them slim. If you want to edit things, you will need to download a command line file editor. Run apt-get update then install an editor like nano with apt-get install nano .","title":"Inspecting a container"},{"location":"docker/#starling-mavros","text":"Finally, we bring in ros2 and uav control from the previous tutorial . In Starling, there exists a core container called starling-mavros which facilitates the communication between the user application and the UAV autopilot in simulation or reality. This container, which you have hopefully run above, uses a Mavros node is to translate between ROS2 for the user, and MAVLINK for the autopilot. We give examples of its use later on.","title":"Starling Mavros"},{"location":"docker/#next-steps","text":"Hopefully you now have a decent understanding of what containerisation is and its purpose within Starling. You have also had a go at using the Docker command line tool to pull, run, build and inspect Starling containers going forward. With all that, we are now at a point where you can start creating your own containers to use!","title":"Next Steps"},{"location":"getting_started/","text":"Getting Started \u00b6 This first tutorial takes you through setting up your machine to be able to run Starling in order to follow the rest of the tutorial. Getting Started Preamble Prerequisits Git and Docker Murmuration - Starling Command Line Interface Cookiecutter Useful Programs Next Steps Preamble \u00b6 For this tutorial, it will be assumed that you have a functional understanding of the Linux, Mac or Windows interface. This includes use of the command line and terminal applications on linux or Mac, and powershell or Windows Subsystem for Linux (WSL) on windows. If you do not feel comfortable with either of these, it is recommended you have a read of this tutorial first: https://docs.starlinguas.dev/tutorials/introduction/#a-brief-introduction-to-linux . This tutorial covers some of the setup shown in this first tutorial in much more detail. Prerequisits \u00b6 Git and Docker \u00b6 You will need to install git to access the software and docker to run it. These are both supported on Windows, Mac and Linux. The Docker Desktop application should also be suitable. Linux users, please verify that the docker-compose tool is installed by running docker-compose --version . If it fails, install using sudo apt-get install docker-compose-plugin . see here . Windows users, it is highly recommended that you also install the Windows Subsystem for Linux (WSL) and use that as the backend for your Docker installations. see here for instructions It is also recommended that you sign up for a github account and a dockerhub account. Murmuration - Starling Command Line Interface \u00b6 You will need to download the Murmuration repository which contains a useful command line interface (cli). This can hopefully abstract away the need to remember all of the different commands. To install, go to your work directory and clone the repository using the command line or gui and run the following commands: git clone https://github.com/StarlingUAS/Murmuration.git # clones locally cd Murmuration In the bin directory of the repository, there is the core cli script named starling . starling includes a further installation script to help install further requirements. This installation script will need to be run using root. See the following guide on which arguments you should give. If running within Murmuration, swap starling for ./bin/starling . However for convenience, you can put starling onto your path. This can be done by adding export PATH=<Path to murmuration>/bin:$PATH into ~/.bashrc followed by source ~/.bashrc , or running the same command locally in the terminal. Then you can use the starling Then to finish the installation run: sudo starling install # or if you have not added starling to path and are in the Murmuration directory. sudo ./bin/starling install Cookiecutter \u00b6 The template generation uses the cookiecutter tool for generating custom projects from a template. To install, first install Python and then run the following: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See cookiecutter installation for further details on different platforms. This will give you access to the cookiecutter command line interface. Useful Programs \u00b6 We highly recommend Visual Studio Code as our editing environment as it has a number of nice features, extensions and allows easy access to terminal windows. Once installed you can run vscode from any directory by running code <my directory> , e.g. code . . Next Steps \u00b6 This should give you all the tools to be able to run the tutorials. Before we dive into creating your own, let us first introduce all the core technologies which Starling makes use of, in order to give you enough background for you all to create your own controllers.","title":"1. Getting Started "},{"location":"getting_started/#getting-started","text":"This first tutorial takes you through setting up your machine to be able to run Starling in order to follow the rest of the tutorial. Getting Started Preamble Prerequisits Git and Docker Murmuration - Starling Command Line Interface Cookiecutter Useful Programs Next Steps","title":"Getting Started"},{"location":"getting_started/#preamble","text":"For this tutorial, it will be assumed that you have a functional understanding of the Linux, Mac or Windows interface. This includes use of the command line and terminal applications on linux or Mac, and powershell or Windows Subsystem for Linux (WSL) on windows. If you do not feel comfortable with either of these, it is recommended you have a read of this tutorial first: https://docs.starlinguas.dev/tutorials/introduction/#a-brief-introduction-to-linux . This tutorial covers some of the setup shown in this first tutorial in much more detail.","title":"Preamble"},{"location":"getting_started/#prerequisits","text":"","title":"Prerequisits"},{"location":"getting_started/#git-and-docker","text":"You will need to install git to access the software and docker to run it. These are both supported on Windows, Mac and Linux. The Docker Desktop application should also be suitable. Linux users, please verify that the docker-compose tool is installed by running docker-compose --version . If it fails, install using sudo apt-get install docker-compose-plugin . see here . Windows users, it is highly recommended that you also install the Windows Subsystem for Linux (WSL) and use that as the backend for your Docker installations. see here for instructions It is also recommended that you sign up for a github account and a dockerhub account.","title":"Git and Docker"},{"location":"getting_started/#murmuration-starling-command-line-interface","text":"You will need to download the Murmuration repository which contains a useful command line interface (cli). This can hopefully abstract away the need to remember all of the different commands. To install, go to your work directory and clone the repository using the command line or gui and run the following commands: git clone https://github.com/StarlingUAS/Murmuration.git # clones locally cd Murmuration In the bin directory of the repository, there is the core cli script named starling . starling includes a further installation script to help install further requirements. This installation script will need to be run using root. See the following guide on which arguments you should give. If running within Murmuration, swap starling for ./bin/starling . However for convenience, you can put starling onto your path. This can be done by adding export PATH=<Path to murmuration>/bin:$PATH into ~/.bashrc followed by source ~/.bashrc , or running the same command locally in the terminal. Then you can use the starling Then to finish the installation run: sudo starling install # or if you have not added starling to path and are in the Murmuration directory. sudo ./bin/starling install","title":"Murmuration - Starling Command Line Interface"},{"location":"getting_started/#cookiecutter","text":"The template generation uses the cookiecutter tool for generating custom projects from a template. To install, first install Python and then run the following: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See cookiecutter installation for further details on different platforms. This will give you access to the cookiecutter command line interface.","title":"Cookiecutter"},{"location":"getting_started/#useful-programs","text":"We highly recommend Visual Studio Code as our editing environment as it has a number of nice features, extensions and allows easy access to terminal windows. Once installed you can run vscode from any directory by running code <my directory> , e.g. code . .","title":"Useful Programs"},{"location":"getting_started/#next-steps","text":"This should give you all the tools to be able to run the tutorials. Before we dive into creating your own, let us first introduce all the core technologies which Starling makes use of, in order to give you enough background for you all to create your own controllers.","title":"Next Steps"},{"location":"multiuav_kubernetes/","text":"Multi-UAV flight with Kubernetes for container deployment \u00b6","title":"8. Multi-UAV flight with Kubernetes for container deployment"},{"location":"multiuav_kubernetes/#multi-uav-flight-with-kubernetes-for-container-deployment","text":"","title":"Multi-UAV flight with Kubernetes for container deployment"},{"location":"next_steps/","text":"Wrapping up and next steps \u00b6","title":"12. Wrapping up and next steps"},{"location":"next_steps/#wrapping-up-and-next-steps","text":"","title":"Wrapping up and next steps"},{"location":"ros2_uav/","text":"An Introduction to ROS2 and UAV Control \u00b6 This tutorial gives a brief overview and background on UAV Control and ROS2. By the end you should have a brief understanding of how a UAV is controlled, how Starling treats a UAV and why and how we use ROS2 to communicate with a UAV An Introduction to ROS2 and UAV Control A Brief Introduction to UAV Control What is a UAV or a Drone How do you control a UAV The Autopilot MAVLink and Autopilot communication A Brief Introduction to ROS Why does ROS exist? What is ROS ROS concepts through an example ROS2 for Starling MAVLINK and ROS with MAVROS Next Steps A Brief Introduction to UAV Control \u00b6 What is a UAV or a Drone \u00b6 A drone or unmanned aerial vehicle (UAV) is an unmanned \"robotic\" vehicle that can be remotely or autonomously controlled. Drones are used for many consumer, industrial, government and military applications (opens new window). These include (non exhaustively): aerial photography/video, carrying cargo, racing, search and surveying etc. Different types of drones exist for use in air, ground, sea, and underwater. These are (more formally) referred to as Unmanned Aerial Vehicles (UAV), Unmanned Aerial Systems (UAS), Unmanned Ground Vehicles (UGV), Unmanned Surface Vehicles (USV), Unmanned Underwater Vehicles (UUV). The \"brain\" of the drone is called an autopilot . It consists of flight stack software running on vehicle controller (\"flight controller\") hardware. A multi-rotor is a specific type of UAV which uses two of more lift-generating rotors to fly. One of the most common will be the Quadrotor which has 4 motors in an 'X' pattern. These UAVs provide much simpler flight control than other types of aerial vehicle. This tutorial focuses on the flight of a simple quadrotor, but Starling can be used to operate many different types of robot. From this point on in this tutorial, 'drone' or 'UAV' will refer to a multi-rotor UAV unless otherwise stated. How do you control a UAV \u00b6 Modified from ardupilot docs A multicopter is a mechanically simple aerial vehicle whose motion is controlled by speeding or slowing multiple downward thrusting motor/propeller units. Combining different thrusts on different rotors allows the vehicle to move in free space with 6 degrees of freedom. However, manually controlling the individual thrusts of each motor in order to move the UAV is incredibly difficult, most would say its impossible even. This instability means that an on-board computer is mandatory for stable flight, as the on-board controller can perform the extreme high-rate control required to keep the drone in the air. In this \"Fly by wire\" paradigm, if the computer isnt working, you aren't flying. This dedicated on-board controller is referred to as the autopilot . This is seperate from a companion computer which is often used to direct the autopilot to achieve higher level mission goals. The autopilot combines data from small on-board MEMs gyroscopes and accelerometers (the same as those found in smart phones) to maintain an accurate estimate of its orientation and position. The quadcopter shown above is the simplest type of multicopter, with each motor/propeller spinning in the opposite direction from the two motors on either side of it (i.e. motors on opposite corners of the frame spin in the same direction). A quadcopter can control its roll and pitch rotation by speeding up two motors on one side and slowing down the other two. So for example if the quadcopter wanted to roll left it would speed up motors on the right side of the frame and slow down the two on the left. Similarly if it wants to rotate forward it speeds up the back two motors and slows down the front two. The copter can turn (aka \u201cyaw\u201d) left or right by speeding up two motors that are diagonally across from each other, and slowing down the other two. Horizontal motion is accomplished by temporarily speeding up/slowing down some motors so that the vehicle is leaning in the direction of desired travel and increasing the overall thrust of all motors so the vehicle shoots forward. Generally the more the vehicle leans, the faster it travels. Altitude is controlled by speeding up or slowing down all motors at the same time. In order to automatically map higher level motions to the thrust of the rotors, a cascading set of PID controllers is designed and provided by the autopilot. These then allow the remote control flight of the vehicle from a transmitter in your pilots hands, or via messages sent by the companion computer The Autopilot \u00b6 There is no universal controller design of converting from user inputs to motor thrust. In the same way, there are numerous other functionalities that an autopilot can cover. These can range from running control loops for gimbals, cameras and other actuation, to high level mission following and safety features. These functionalities are bundled into specific autopilot firmwares which each offer a slightly different set of features, as well as differing user interfaces each with their advantages and drawbacks. The two current most common autopilot firmware's in use in research settings are Ardupilot which offers the Arducopter firmware, and PX4 which offers Multicopter firmware. Both these firmwares are very extensive and cover numerous use cases. However, for our purposes we will only cover enabling autonomous flight through observing the mode of the autpilot. Both Ardupilot and PX4 use the concept of flight modes, where each mode operates a supports different levels or types of flight stabilisation and/or autonomous functions. Traditionally this is for pilots to change between different controller layouts for different applications. It's necessary to change to the correct mode for safe and controllable flight. The following table shows the most often used flight modes within Starling. Ardupilot Mode PX4 Mode Functionality stabilized manual Full manual control with RC sticks being sent directly to control roll, pitch, yaw and height PosHold position UAV uses onboard sensing to stay in place, RC sticks used to translate position loiter auto.hold Automatic mode where UAV stays in the same location until further instructions given. land auto.land Automatic mode which attempts to land the UAV Guided offboard Navigates to setpoints sent to it by ground control or companion computer Our controllers will all ask the autopilot to switch into guided or offboard mode in order to control from the companion computer. Often they have safety elements build in which mean that the autopilot must receive instructions at a certain rate (2Hz) otherwise the autopilot will switch to loiter or land. As mentioned before, the firmware provides a given cascading PID controller for converting high level commands to motor thrusts. As a controller developer, it is also useful to understand the differences between the Ardupilot and PX4 controllers and what real world impacts that has. Thankfully in most of Starling's targeted applications we only require position control which works fairly consistently between the two firmwares. In our own work, it has generally been noted that Ardupilot seems to be more suitable for outdoor flight, and PX4 for indoor flight. For this tutorial we will be developing an controller for indoor multi-vehicle flight and so we will assume the use of PX4. If interested in outdoor flight with Ardupilot, check out this tutorial which uses Starling with Ardupilot to simulate outdoor drone flight over a volcano. MAVLink and Autopilot communication \u00b6 Once in guided or offboard mode, the autopilot expects communications using the MAVLINK protocol . Traditionally this would have been used for a ground control station (GCS) to send commands to a UAV over a telemetry link. However, now it has also developed into a protocol for commanding the autopilot from an onboard companion computer over a USB or serial connection too. In Starling, both methods of communication between GCS or companion computer are supported. The MAVLink protocol is a set of preset commands which compatible firmwares understand and react to. However, it is often verbose and not-intuitive to develop applications with, as well as requiring a lot of prior knowledge about the state of the system. For example, it is neccesary to send a number of specific messages in order to receive individual data streams on vehicle status, location, global location and so on. These are often missed and cause lots of headaches for developers. Starling aims to streamline this through the use of the Robot Operating System so users no longer need to interact with MAVLink and the autopilot directly. A Brief Introduction to ROS \u00b6 This sections is adapted from this article ROS stands for the Robot Operating System, yet it isn't an actual operating system. It's a framework designed to expedite the development time of robot platforms. To understand what ROS is, we should understand why ROS exists in the first place. Why does ROS exist? \u00b6 In general, software developers avoid hardware like the plague. It's messy, doesn't have consistent behavior, and there's no ctrl-z in sight. Most beginner programmers think you have to have a deep knowledge of electronics and even mechanics to program robots. They think that the hardware and software are so tightly coupled, you have to know both in depth to build anything useful. Software developers became software developers for a reason, so they don't have to deal with hardware. For example, lets say you have to debug a faulty sensor. You first have to take out the sensor from the enclosure, test the sensor thoroughly with a multi meter and various test cases, document its behavior, then examine the hardware -level code to ensure that there were no bugs, and so on. That's a lot of interaction with the hardware that's not fun for someone who just wants to write some cool software. It's harder to attract good programmers if the programming is coupled deeply with hardware. This is where ROS comes into play. With ROS, you can completely abstract the hardware from software, and instead interact with an API that gives access to that data. You can forget about the hardware, and focus on developing the software that makes the robot do what you want. What is ROS \u00b6 ROS is essentially a framework that sits on top of an operating system which defines how particular ROS compatible programs communicate and share data with each other. Essentially ROS defines an interface between which compatible programs can communicate and interact with each other. Over the years that ROS has existed, many people have developed thousands of ROS compatible packages which can be used in a modular fashion. ROS concepts through an example \u00b6 To make it more concrete, imagine that on your drone you have a camera. There are also two processes which require, as inputs, that camera image. Say, a machine learning program, and a position estimation program. Traditionally, you would have to manually serialise (compress) and stream the image over a port which the other two programs could read from. But if the port changes or, say, the camera changes, lots of things have to be reconfigured. However, this sort of interaction can be made streamlined in ROS. Let us consider the programs we have as ROS nodes , i.e. a program which is responsible for one single modular purpose, with particular inputs or outputs: A camera image streaming node OUT: camera image A machine vision system for recognising objects IN: camera image OUT: list of recognised objects A simultaneous localisation and mapping system. IN: camera image OUT: vehicle position These outputs of a node define ROS topics , i.e. a single stream of one type of data. Each topic has a particular name which can be referred to. In our example, some of the topics might be: /drone/camera for the camera image /drone/recognised_objects for the machine vision system /drone/slam_position for the SLAM system Then, we see that there are two avenues of communication created from these node inputs and outputs. graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Machine Vision] node --in--> D[SLAM] style node fill:#f9f,stroke:#333,stroke-width:4px Now ROS follows a publisher/subscriber model of communication. What that means is that nodes publish data to topics as outputs. But that data is only sent across the network if a different nodes also subscribes to the same topic. So in our example we end up having A camera image streaming node OUT: publishing to /drone/camera A machine vision system for recognising objects IN: subscribed to /drone/camera OUT: publishing to /drone/recognised_objects A simultaneous localisation and mapping system. IN: subscribed to /drone/camera OUT: publishing to /drone/slam_position graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Vision] C -->|out| node1[drone/recognised_objects] node --in--> D[SLAM] D -->|out| node2[drone/slam_position] style node fill:#f9f,stroke:#333,stroke-width:4px style node1 fill:#f9f,stroke:#333,stroke-width:4px style node2 fill:#f9f,stroke:#333,stroke-width:4px Finally, the data that is sent is not just anything. The data or message is a specifically templated packet of data containing things specified for that paricular use case. In our example for /drone/slam_position topic, the message might be of type geometry_msgs/msg/Point.msg which is defined like so: # This contains the position of a point in free space float64 x float64 y float64 z In other words the message that the /drone/slam_position topic publishes must have a msg.x , msg.y and msg.z field, and the subscriber will only receivea message with those fields. There are a number of messages in the standard ROS library, but many libraries also define their own - as have we in some parts of Starling. This can be summarised in this diagram from the ROS tutorials demonstrates it very nicely: The bottom half of this shows how topics get sent from a publisher to a subscriber. Interestingly, if you put two topics together, you get some notion of two way communication. This is the basis of a service which can be seen in the top of the diagram. A service is made of a Request topic and a Response topic, but functions as a single communication type to the user. Similar to messages, a service has a defined request and response types (e.g. see std_srvs/srv/SetBool.srv ). A service request will often wait until a response is received before continuing. Note that everything happens asyncronously and in parallel, when a node subscribes or sends a requests, it doesn't know when the response will arrive. It only knows it will (hopefully) arrive at some point. When a packet is received the subscriber can then run a method - this method is usually known as a callback , but that will be covered in a later tutorial. Finally, each node is configured by a set of parameters which are broadcast to all other nodes. Parameters are often configuration values for particular methods in a node, and can sometimes be changed on startup (or dynamically through a service), to allow the node to provide adjustable functionality. For example the value of a timeout or frequency of a loop. So in summary, the key concepts and terminology are: Nodes Topics Publishers and Subscribers Messages Services Parameters ROS2 for Starling \u00b6 There are 2 versions of ROS: ROS1 and ROS2. ROS1, initially created in 2007 by Willow Garage, has become huge among the open source robotics community. However over the years they realised that there are a number of important features which are missing - and adding all of these would simply break ROS1. Also the most recent ROS1 distribution (ROS Noetic) is soon to reach the end of its supported life (EOL 2025) with no more ROS1 there after! (See this article for more details!) Therefore, to future proof the system, and to ensure all users get a well rounded experience that will hopefully translate to industry experience, Starling has been implemented in ROS2. Specifically, Starling uses the Foxy Fitzroy Long Term Support (LTS) distribution throughout. There are some interesting changes between ROS1 and ROS2, but the core elements described above remain identical. For those interested, ROS2 follows a much more decentralised paradigm, and does not require a central ROSnode as it uses the distributed DDS communication protocol for its internal communication. All nodes therefore broadcast their own topics allowing for easy decentralised discovery - perfect for multi-robot applications. Note: Main thing to be aware of is if you are debugging and searching for ROS questions on the internet, be aware that there are many existing questions for ROS1 which will no longer apply for ROS2. MAVLINK and ROS with MAVROS \u00b6 Coming back round to flying drones, we mentioned in that we wanted to use ROS to avoid having to manually communicate with the autopilot using MAVLINK. Starling uses the MAVROS ROS package to do exactly that. For the autpilot, it automatically sets up a connection and translates higher level ROS commands into MAVLINK commands. For controller developers, Mavros provides a known and consistent interface through a set of topics, services and parameters to interact with. These include high level actions such as requesting the vehicle's state, local position, gps position, as well as setting setpoints for the vehicle to visit. A couple of useful topics are in the following table: Name Topic Message Type Functionality State mavros/state mavros_msgs/msg/State Get's the current state and flight mode of the vehicle Local Position mavros/local_position/pose geometry_msgs/msg/PoseStamped Get the UAVs current coordinate position after sensor fusion GPS Position mavros/global_position/global sensor_msgs/msg/NavSatFix Get the UAVs current lat,long (if enabled) Position Setpoint mavros/setpoint_position/local geometry_msgs/msg/PoseStamped Send a target coordinate and orientation for the vehicle to fly to immediately Set Flight Mode mavros/set_mode mavros_msgs/srv/SetMode A service which sets the flight mode of the autopilot Set Data Stream Rate mavros/set_stream_rate mavros_msgs/srv/StreamRate A service which starts the data stream from the autopilot and sets its rate Sometimes, you may need to send raw MAVlink back to the Autopilot to enable some non-standard functionality. This can also be done through the MAVROS node too. As we are now utilising ROS, this allows us to make the most of the full ROS ecosystem in developing UAV applications. Next Steps \u00b6 Hopefully now you have a basic understanding of what a drone is and how they are controller, the function and purpose of an autopilot, as well as how ROS functions and can be used. If you want some early hands on experience with ROS before delving further into Starling, we highly recommend the offical ros2 tutorials . We have one more theory topic before you can start creating your own Starling projects, where we will be discussing how Starling uses and encapsulates ROS functionality.","title":"2. ROS2 and UAV Control"},{"location":"ros2_uav/#an-introduction-to-ros2-and-uav-control","text":"This tutorial gives a brief overview and background on UAV Control and ROS2. By the end you should have a brief understanding of how a UAV is controlled, how Starling treats a UAV and why and how we use ROS2 to communicate with a UAV An Introduction to ROS2 and UAV Control A Brief Introduction to UAV Control What is a UAV or a Drone How do you control a UAV The Autopilot MAVLink and Autopilot communication A Brief Introduction to ROS Why does ROS exist? What is ROS ROS concepts through an example ROS2 for Starling MAVLINK and ROS with MAVROS Next Steps","title":"An Introduction to ROS2 and UAV Control"},{"location":"ros2_uav/#a-brief-introduction-to-uav-control","text":"","title":"A Brief Introduction to UAV Control"},{"location":"ros2_uav/#what-is-a-uav-or-a-drone","text":"A drone or unmanned aerial vehicle (UAV) is an unmanned \"robotic\" vehicle that can be remotely or autonomously controlled. Drones are used for many consumer, industrial, government and military applications (opens new window). These include (non exhaustively): aerial photography/video, carrying cargo, racing, search and surveying etc. Different types of drones exist for use in air, ground, sea, and underwater. These are (more formally) referred to as Unmanned Aerial Vehicles (UAV), Unmanned Aerial Systems (UAS), Unmanned Ground Vehicles (UGV), Unmanned Surface Vehicles (USV), Unmanned Underwater Vehicles (UUV). The \"brain\" of the drone is called an autopilot . It consists of flight stack software running on vehicle controller (\"flight controller\") hardware. A multi-rotor is a specific type of UAV which uses two of more lift-generating rotors to fly. One of the most common will be the Quadrotor which has 4 motors in an 'X' pattern. These UAVs provide much simpler flight control than other types of aerial vehicle. This tutorial focuses on the flight of a simple quadrotor, but Starling can be used to operate many different types of robot. From this point on in this tutorial, 'drone' or 'UAV' will refer to a multi-rotor UAV unless otherwise stated.","title":"What is a UAV or a Drone"},{"location":"ros2_uav/#how-do-you-control-a-uav","text":"Modified from ardupilot docs A multicopter is a mechanically simple aerial vehicle whose motion is controlled by speeding or slowing multiple downward thrusting motor/propeller units. Combining different thrusts on different rotors allows the vehicle to move in free space with 6 degrees of freedom. However, manually controlling the individual thrusts of each motor in order to move the UAV is incredibly difficult, most would say its impossible even. This instability means that an on-board computer is mandatory for stable flight, as the on-board controller can perform the extreme high-rate control required to keep the drone in the air. In this \"Fly by wire\" paradigm, if the computer isnt working, you aren't flying. This dedicated on-board controller is referred to as the autopilot . This is seperate from a companion computer which is often used to direct the autopilot to achieve higher level mission goals. The autopilot combines data from small on-board MEMs gyroscopes and accelerometers (the same as those found in smart phones) to maintain an accurate estimate of its orientation and position. The quadcopter shown above is the simplest type of multicopter, with each motor/propeller spinning in the opposite direction from the two motors on either side of it (i.e. motors on opposite corners of the frame spin in the same direction). A quadcopter can control its roll and pitch rotation by speeding up two motors on one side and slowing down the other two. So for example if the quadcopter wanted to roll left it would speed up motors on the right side of the frame and slow down the two on the left. Similarly if it wants to rotate forward it speeds up the back two motors and slows down the front two. The copter can turn (aka \u201cyaw\u201d) left or right by speeding up two motors that are diagonally across from each other, and slowing down the other two. Horizontal motion is accomplished by temporarily speeding up/slowing down some motors so that the vehicle is leaning in the direction of desired travel and increasing the overall thrust of all motors so the vehicle shoots forward. Generally the more the vehicle leans, the faster it travels. Altitude is controlled by speeding up or slowing down all motors at the same time. In order to automatically map higher level motions to the thrust of the rotors, a cascading set of PID controllers is designed and provided by the autopilot. These then allow the remote control flight of the vehicle from a transmitter in your pilots hands, or via messages sent by the companion computer","title":"How do you control a UAV"},{"location":"ros2_uav/#the-autopilot","text":"There is no universal controller design of converting from user inputs to motor thrust. In the same way, there are numerous other functionalities that an autopilot can cover. These can range from running control loops for gimbals, cameras and other actuation, to high level mission following and safety features. These functionalities are bundled into specific autopilot firmwares which each offer a slightly different set of features, as well as differing user interfaces each with their advantages and drawbacks. The two current most common autopilot firmware's in use in research settings are Ardupilot which offers the Arducopter firmware, and PX4 which offers Multicopter firmware. Both these firmwares are very extensive and cover numerous use cases. However, for our purposes we will only cover enabling autonomous flight through observing the mode of the autpilot. Both Ardupilot and PX4 use the concept of flight modes, where each mode operates a supports different levels or types of flight stabilisation and/or autonomous functions. Traditionally this is for pilots to change between different controller layouts for different applications. It's necessary to change to the correct mode for safe and controllable flight. The following table shows the most often used flight modes within Starling. Ardupilot Mode PX4 Mode Functionality stabilized manual Full manual control with RC sticks being sent directly to control roll, pitch, yaw and height PosHold position UAV uses onboard sensing to stay in place, RC sticks used to translate position loiter auto.hold Automatic mode where UAV stays in the same location until further instructions given. land auto.land Automatic mode which attempts to land the UAV Guided offboard Navigates to setpoints sent to it by ground control or companion computer Our controllers will all ask the autopilot to switch into guided or offboard mode in order to control from the companion computer. Often they have safety elements build in which mean that the autopilot must receive instructions at a certain rate (2Hz) otherwise the autopilot will switch to loiter or land. As mentioned before, the firmware provides a given cascading PID controller for converting high level commands to motor thrusts. As a controller developer, it is also useful to understand the differences between the Ardupilot and PX4 controllers and what real world impacts that has. Thankfully in most of Starling's targeted applications we only require position control which works fairly consistently between the two firmwares. In our own work, it has generally been noted that Ardupilot seems to be more suitable for outdoor flight, and PX4 for indoor flight. For this tutorial we will be developing an controller for indoor multi-vehicle flight and so we will assume the use of PX4. If interested in outdoor flight with Ardupilot, check out this tutorial which uses Starling with Ardupilot to simulate outdoor drone flight over a volcano.","title":"The Autopilot"},{"location":"ros2_uav/#mavlink-and-autopilot-communication","text":"Once in guided or offboard mode, the autopilot expects communications using the MAVLINK protocol . Traditionally this would have been used for a ground control station (GCS) to send commands to a UAV over a telemetry link. However, now it has also developed into a protocol for commanding the autopilot from an onboard companion computer over a USB or serial connection too. In Starling, both methods of communication between GCS or companion computer are supported. The MAVLink protocol is a set of preset commands which compatible firmwares understand and react to. However, it is often verbose and not-intuitive to develop applications with, as well as requiring a lot of prior knowledge about the state of the system. For example, it is neccesary to send a number of specific messages in order to receive individual data streams on vehicle status, location, global location and so on. These are often missed and cause lots of headaches for developers. Starling aims to streamline this through the use of the Robot Operating System so users no longer need to interact with MAVLink and the autopilot directly.","title":"MAVLink and Autopilot communication"},{"location":"ros2_uav/#a-brief-introduction-to-ros","text":"This sections is adapted from this article ROS stands for the Robot Operating System, yet it isn't an actual operating system. It's a framework designed to expedite the development time of robot platforms. To understand what ROS is, we should understand why ROS exists in the first place.","title":"A Brief Introduction to ROS"},{"location":"ros2_uav/#why-does-ros-exist","text":"In general, software developers avoid hardware like the plague. It's messy, doesn't have consistent behavior, and there's no ctrl-z in sight. Most beginner programmers think you have to have a deep knowledge of electronics and even mechanics to program robots. They think that the hardware and software are so tightly coupled, you have to know both in depth to build anything useful. Software developers became software developers for a reason, so they don't have to deal with hardware. For example, lets say you have to debug a faulty sensor. You first have to take out the sensor from the enclosure, test the sensor thoroughly with a multi meter and various test cases, document its behavior, then examine the hardware -level code to ensure that there were no bugs, and so on. That's a lot of interaction with the hardware that's not fun for someone who just wants to write some cool software. It's harder to attract good programmers if the programming is coupled deeply with hardware. This is where ROS comes into play. With ROS, you can completely abstract the hardware from software, and instead interact with an API that gives access to that data. You can forget about the hardware, and focus on developing the software that makes the robot do what you want.","title":"Why does ROS exist?"},{"location":"ros2_uav/#what-is-ros","text":"ROS is essentially a framework that sits on top of an operating system which defines how particular ROS compatible programs communicate and share data with each other. Essentially ROS defines an interface between which compatible programs can communicate and interact with each other. Over the years that ROS has existed, many people have developed thousands of ROS compatible packages which can be used in a modular fashion.","title":"What is ROS"},{"location":"ros2_uav/#ros-concepts-through-an-example","text":"To make it more concrete, imagine that on your drone you have a camera. There are also two processes which require, as inputs, that camera image. Say, a machine learning program, and a position estimation program. Traditionally, you would have to manually serialise (compress) and stream the image over a port which the other two programs could read from. But if the port changes or, say, the camera changes, lots of things have to be reconfigured. However, this sort of interaction can be made streamlined in ROS. Let us consider the programs we have as ROS nodes , i.e. a program which is responsible for one single modular purpose, with particular inputs or outputs: A camera image streaming node OUT: camera image A machine vision system for recognising objects IN: camera image OUT: list of recognised objects A simultaneous localisation and mapping system. IN: camera image OUT: vehicle position These outputs of a node define ROS topics , i.e. a single stream of one type of data. Each topic has a particular name which can be referred to. In our example, some of the topics might be: /drone/camera for the camera image /drone/recognised_objects for the machine vision system /drone/slam_position for the SLAM system Then, we see that there are two avenues of communication created from these node inputs and outputs. graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Machine Vision] node --in--> D[SLAM] style node fill:#f9f,stroke:#333,stroke-width:4px Now ROS follows a publisher/subscriber model of communication. What that means is that nodes publish data to topics as outputs. But that data is only sent across the network if a different nodes also subscribes to the same topic. So in our example we end up having A camera image streaming node OUT: publishing to /drone/camera A machine vision system for recognising objects IN: subscribed to /drone/camera OUT: publishing to /drone/recognised_objects A simultaneous localisation and mapping system. IN: subscribed to /drone/camera OUT: publishing to /drone/slam_position graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Vision] C -->|out| node1[drone/recognised_objects] node --in--> D[SLAM] D -->|out| node2[drone/slam_position] style node fill:#f9f,stroke:#333,stroke-width:4px style node1 fill:#f9f,stroke:#333,stroke-width:4px style node2 fill:#f9f,stroke:#333,stroke-width:4px Finally, the data that is sent is not just anything. The data or message is a specifically templated packet of data containing things specified for that paricular use case. In our example for /drone/slam_position topic, the message might be of type geometry_msgs/msg/Point.msg which is defined like so: # This contains the position of a point in free space float64 x float64 y float64 z In other words the message that the /drone/slam_position topic publishes must have a msg.x , msg.y and msg.z field, and the subscriber will only receivea message with those fields. There are a number of messages in the standard ROS library, but many libraries also define their own - as have we in some parts of Starling. This can be summarised in this diagram from the ROS tutorials demonstrates it very nicely: The bottom half of this shows how topics get sent from a publisher to a subscriber. Interestingly, if you put two topics together, you get some notion of two way communication. This is the basis of a service which can be seen in the top of the diagram. A service is made of a Request topic and a Response topic, but functions as a single communication type to the user. Similar to messages, a service has a defined request and response types (e.g. see std_srvs/srv/SetBool.srv ). A service request will often wait until a response is received before continuing. Note that everything happens asyncronously and in parallel, when a node subscribes or sends a requests, it doesn't know when the response will arrive. It only knows it will (hopefully) arrive at some point. When a packet is received the subscriber can then run a method - this method is usually known as a callback , but that will be covered in a later tutorial. Finally, each node is configured by a set of parameters which are broadcast to all other nodes. Parameters are often configuration values for particular methods in a node, and can sometimes be changed on startup (or dynamically through a service), to allow the node to provide adjustable functionality. For example the value of a timeout or frequency of a loop. So in summary, the key concepts and terminology are: Nodes Topics Publishers and Subscribers Messages Services Parameters","title":"ROS concepts through an example"},{"location":"ros2_uav/#ros2-for-starling","text":"There are 2 versions of ROS: ROS1 and ROS2. ROS1, initially created in 2007 by Willow Garage, has become huge among the open source robotics community. However over the years they realised that there are a number of important features which are missing - and adding all of these would simply break ROS1. Also the most recent ROS1 distribution (ROS Noetic) is soon to reach the end of its supported life (EOL 2025) with no more ROS1 there after! (See this article for more details!) Therefore, to future proof the system, and to ensure all users get a well rounded experience that will hopefully translate to industry experience, Starling has been implemented in ROS2. Specifically, Starling uses the Foxy Fitzroy Long Term Support (LTS) distribution throughout. There are some interesting changes between ROS1 and ROS2, but the core elements described above remain identical. For those interested, ROS2 follows a much more decentralised paradigm, and does not require a central ROSnode as it uses the distributed DDS communication protocol for its internal communication. All nodes therefore broadcast their own topics allowing for easy decentralised discovery - perfect for multi-robot applications. Note: Main thing to be aware of is if you are debugging and searching for ROS questions on the internet, be aware that there are many existing questions for ROS1 which will no longer apply for ROS2.","title":"ROS2 for Starling"},{"location":"ros2_uav/#mavlink-and-ros-with-mavros","text":"Coming back round to flying drones, we mentioned in that we wanted to use ROS to avoid having to manually communicate with the autopilot using MAVLINK. Starling uses the MAVROS ROS package to do exactly that. For the autpilot, it automatically sets up a connection and translates higher level ROS commands into MAVLINK commands. For controller developers, Mavros provides a known and consistent interface through a set of topics, services and parameters to interact with. These include high level actions such as requesting the vehicle's state, local position, gps position, as well as setting setpoints for the vehicle to visit. A couple of useful topics are in the following table: Name Topic Message Type Functionality State mavros/state mavros_msgs/msg/State Get's the current state and flight mode of the vehicle Local Position mavros/local_position/pose geometry_msgs/msg/PoseStamped Get the UAVs current coordinate position after sensor fusion GPS Position mavros/global_position/global sensor_msgs/msg/NavSatFix Get the UAVs current lat,long (if enabled) Position Setpoint mavros/setpoint_position/local geometry_msgs/msg/PoseStamped Send a target coordinate and orientation for the vehicle to fly to immediately Set Flight Mode mavros/set_mode mavros_msgs/srv/SetMode A service which sets the flight mode of the autopilot Set Data Stream Rate mavros/set_stream_rate mavros_msgs/srv/StreamRate A service which starts the data stream from the autopilot and sets its rate Sometimes, you may need to send raw MAVlink back to the Autopilot to enable some non-standard functionality. This can also be done through the MAVROS node too. As we are now utilising ROS, this allows us to make the most of the full ROS ecosystem in developing UAV applications.","title":"MAVLINK and ROS with MAVROS"},{"location":"ros2_uav/#next-steps","text":"Hopefully now you have a basic understanding of what a drone is and how they are controller, the function and purpose of an autopilot, as well as how ROS functions and can be used. If you want some early hands on experience with ROS before delving further into Starling, we highly recommend the offical ros2 tutorials . We have one more theory topic before you can start creating your own Starling projects, where we will be discussing how Starling uses and encapsulates ROS functionality.","title":"Next Steps"},{"location":"simulation/","text":"Simulation and the Digital Double \u00b6 In this tutorial we will cover how a UAV simulation works and introduce Gazebo, the physics simulator that we use in Starling. By the end you should know the different parts of the simulator and how to run it locally. Simulation and the Digital Double UAV Simulation Software in the loop Gazebo BRL Digital Double Running the local simulator What is in the local simulation Inspecting the local simulation Next Steps UAV Simulation \u00b6 Often UAV Simulation is solely focussed on trying to recreate the dynamics of UAV flight. In Starling however, we have decided to leave that to the physics simulator experts, and instead focus on the Simulation of systems and architecture involved with UAV flight. This is with the goal to make transferring control from simulation to real hardware as streamlined and straight forward as possible. In the previous section on UAV control we said that a core part of UAV control is the Autopilot . It is a physical computer which takes sensor inputs to create motor voltages to spin the motor. To re-create this as close as possible, we would like to simulate all of this to ensure that the operation of the uav is as close to reality as possible. Software in the loop \u00b6 Thankfully, both Ardupilot and SITL can be run as software in the loop or SITL simulation where the flight stack that would run on the autopilot, runs on your local computer. Simulators allow flight code to control a computer modeled vehicle in a simulated \"world\". You can interact with this vehicle just as you might with a real vehicle, using QGroundControl, an offboard API such as ROS, or a radio controller/gamepad. Simulation is a quick, easy, and most importantly, safe way to test changes to your controller before attempting to fly in the real world. It is also a good way to start flying when you haven't yet got a vehicle to experiment with or dont want to damage it. From a Starling perspective, the MAVROS container does not distinguish between running on a real vehicle or running on SITL as both still speak the same version of MAVLINK. The MAVROS container internally handles connecting to the correct source. Gazebo \u00b6 Alongisde the SITL, a physics engine is also required for it to run against. Together the simulation is often performed in lockstep where the SITL will generate a motion in one step based on the simulator state, follwed by the simulator advancing by one step based on that motion. In Starling, we primarily use the gazebo physics and visualisation engine as it is one of the most commonly out there currently in the robotics space. Starling is designed with simulator modularity in mind, and it's hoped that in the future other simulators will also be supported! Starling provides a number of containers which have Gazebo pre configured and installed, along with a web based interface for viewing the simulation in progress. In this tutorial, we will be using one container in particular. BRL Digital Double \u00b6 As well as simulating the vehicles themselves, it is also important to simulate the environment in which we are operating. For this tutorial we will be flying the Bristol Robotics Laboratory (BRL) flight arena, and therefore we provide a digital double of that space here , and it is contained within the following container: uobflightlabstarling/uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This will place you into a space where the exact measurements match the real world version of the flight arena. Flight arena is 15.6m x 11.8m x 5m (x, y, z) tall, origin is offset by (0.5, 0.7, 0.0) from space center. The coordinate space is x positive is up and y postivie is left (w.r.t the ascii figure). _________________________________ | | | | | | |_ L| |C| | | | |__|____________ | |___|_V_|___|___| | | _____ _____| |_ _____ ______|__E__|_____| Running the local simulator \u00b6 With all of that in mind, we can now run the full simulation of a single UAV in the flight arena locally on your machine. Go to your new Starling application, and you should see a deployment folder. Inside there exists a docker-compose.yml file. A docker compose file is used to specify the running of multiple containers in one go, instead of having to run a bunch of them manually! To ensure that you have the latest containers, we should pull all of the used ones from docker hub explicitly: docker-compose -f deployment/docker-compose.yml pull This can take a while, especially if the internet is slow. Once downloaded, you can then run the simulator stack with the up command: docker-compose -f deployment/docker-compose.yml up If you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml --pull start Note: depending on what you also have running, you may receive a port in use error. If it is the port for simhost (8080), rosbridge (9090) or the ui (3000), you can change it as <local_port>:<container_port> . Note: Stop the simulator with ctrl+c Once you have run, you should see a lot of text fly by in the terminal! Hopefully none of it is red... To access the simulator, go to localhost:8080 , and to access the simple UI, go to localhost:3000 . The UI contains a simple Go and Stop button which both send topics of /mission_start and /emergency_stop respectively. What is in the local simulation \u00b6 Awesome you now have the local simulator running... but what have you actually run? Let's take you through the docker compose file: uobflightlabstarling/starling-sim-iris-px4-flightarena : As mentioned is the gazebo image which contains the model of the flying arena, as well as the model of the UAV. On startup, it spawns the arena and spawns a single vehicle into it. uobflightlabstarling/starling-sim-px4-sitl : Is the container which runs the PX4 Software In The Loop mentioned earlier on. Throug the environment variables, it knows to connect to the gazebo container for physics, and then knows to expect the mavros container for offboard commands. uobflightlabstarling/starling-mavros : Is the container which runs mavros mentioned in a previous tutorial. It serves as the connection point between the SITL and your own controller code. uobflightlabstarling/rosbridge-suite : Is the gateway for web ros applications like the UI to connect to ROS. uobflightlabstarling/starling-ui-example : Is the example web application with a simple interface. Inspecting the local simulation \u00b6 To verify the functionality of the simulator, we can have a look at some of the ROS Topics that are being sent around. Let us do this by exec -ing into one of the containers. So again: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca5384b42f41 uobflightlabstarling/starling-mavros:nightly \"/ros_entrypoint.sh \u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:5760->5760/tcp deployment_mavros_1 633d71686da7 uobflightlabstarling/starling-sim-px4-sitl:nightly \"/entrypoint.sh /bin\u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:18570->18570/udp deployment_sitl_1 a462241ba16f uobflightlabstarling/starling-sim-iris-px4-flightarena:latest \"/entrypoint.sh ros2\u2026\" 9 seconds ago Up 8 seconds 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp deployment_simhost_1 51adc525e085 uobflightlabstarling/starling-ui-example:latest \"/ros_entrypoint.sh \u2026\" 29 minutes ago Up 8 seconds 9090/tcp, 0.0.0.0:3001->3000/tcp deployment_starling-ui-example_1 f1208345c980 uobflightlabstarling/rosbridge-suite:latest \"/ros_entrypoint.sh \u2026\" 36 minutes ago Up 9 seconds 0.0.0.0:9090->9090/tcp deployment_rosbridge-suite_1 Choosing the starling-mavros container, we can exec into that and run the following: docker exec -it ca5384b42f41 bash root@ca5384b42f41:/ros_ws# . /opt/ros/foxy/setup.bash root@ca5384b42f41:/ros_ws# ros2 topic list /client_count /clock /connected_clients /emergency_stop /link_states /model_states /parameter_events /performance_metrics /rosout /vehicle_1/mavlink/from /vehicle_1/mavlink/to /vehicle_1/mavros/battery /vehicle_1/mavros/distance_sensor/hrlv_ez4_sonar /vehicle_1/mavros/distance_sensor/lidarlite_laser /vehicle_1/mavros/distance_sensor/rangefinder /vehicle_1/mavros/distance_sensor/temperature /vehicle_1/mavros/extended_state /vehicle_1/mavros/global_position/global /vehicle_1/mavros/image/camera_image /vehicle_1/mavros/imu/data /vehicle_1/mavros/local_position/accel /vehicle_1/mavros/local_position/odom /vehicle_1/mavros/local_position/pose /vehicle_1/mavros/local_position/pose_cov /vehicle_1/mavros/local_position/velocity_body /vehicle_1/mavros/local_position/velocity_body_cov /vehicle_1/mavros/local_position/velocity_local /vehicle_1/mavros/manual_control/control /vehicle_1/mavros/manual_control/send /vehicle_1/mavros/mission/reached /vehicle_1/mavros/mission/waypoints /vehicle_1/mavros/px4flow/ground_distance /vehicle_1/mavros/px4flow/raw/optical_flow_rad /vehicle_1/mavros/safety_area /vehicle_1/mavros/setpoint_accel/accel /vehicle_1/mavros/setpoint_attitude/attitude /vehicle_1/mavros/setpoint_attitude/cmd_vel /vehicle_1/mavros/setpoint_attitude/thrust /vehicle_1/mavros/setpoint_position/global /vehicle_1/mavros/setpoint_position/global_to_local /vehicle_1/mavros/setpoint_position/local /vehicle_1/mavros/setpoint_raw/attitude /vehicle_1/mavros/setpoint_raw/global /vehicle_1/mavros/setpoint_raw/local /vehicle_1/mavros/setpoint_velocity/cmd_vel_unstamped /vehicle_1/mavros/state /vehicle_1/mavros/vision_pose/pose /vehicle_1/mavros/vision_pose/pose_cov /vehicle_1/mavros/vision_speed/speed_twist /vehicle_1/mavros/vision_speed/speed_vector This list a list of all the topics currently being broadcast onto the system. Similarly we can inspect the current list of nodes: root@ca5384b42f41:/ros_ws# ros2 node list /gazebo /gazebo_vehicle_state_plugin /motion_tracker_sim /rosapi /rosapi /rosbridge_websocket /vehicle_1/estop /vehicle_1/ros_bridge and many others. We can also have a look at some of the topics. For example, if we wanted to look at the state of a vehicle 1, we would have a look at /vehicle_1/mavros/local_posiiton/pose (Press ctrl+c to stop the stream). root@ca5384b42f41:/ros_ws# ros2 topic echo /vehicle_1/mavros/local_posiiton/pose --- header: stamp: sec: 1655741007 nanosec: 589603584 frame_id: map pose: position: x: -0.010252323932945728 y: -0.025252731516957283 z: -0.019200336188077927 orientation: x: -0.0019689216589022533 y: -0.0020565663184938785 z: 0.0005801513697525905 w: -0.9999958103477264 --- header: stamp: sec: 1655741007 nanosec: 617603584 frame_id: map pose: position: x: -0.01022176630795002 y: -0.02509368769824505 z: -0.018872130662202835 orientation: x: -0.0019977603981865205 y: -0.0021082978655832646 z: 0.0006137002611672492 w: -0.9999956417603324 --- ... Have a play around an investigate the other topics! Finally to stop the simulator, you can simply run ctrl+c in the terminal running the simulator. Next Steps \u00b6 This tutorial should have introduced you to how UAV simulation works and the gazebo simulator we use in Starling. It should have also showed you how to run the simulator, so that you can test the controller you will be developing in the next part.","title":"5. Simulation and the Digital Double"},{"location":"simulation/#simulation-and-the-digital-double","text":"In this tutorial we will cover how a UAV simulation works and introduce Gazebo, the physics simulator that we use in Starling. By the end you should know the different parts of the simulator and how to run it locally. Simulation and the Digital Double UAV Simulation Software in the loop Gazebo BRL Digital Double Running the local simulator What is in the local simulation Inspecting the local simulation Next Steps","title":"Simulation and the Digital Double"},{"location":"simulation/#uav-simulation","text":"Often UAV Simulation is solely focussed on trying to recreate the dynamics of UAV flight. In Starling however, we have decided to leave that to the physics simulator experts, and instead focus on the Simulation of systems and architecture involved with UAV flight. This is with the goal to make transferring control from simulation to real hardware as streamlined and straight forward as possible. In the previous section on UAV control we said that a core part of UAV control is the Autopilot . It is a physical computer which takes sensor inputs to create motor voltages to spin the motor. To re-create this as close as possible, we would like to simulate all of this to ensure that the operation of the uav is as close to reality as possible.","title":"UAV Simulation"},{"location":"simulation/#software-in-the-loop","text":"Thankfully, both Ardupilot and SITL can be run as software in the loop or SITL simulation where the flight stack that would run on the autopilot, runs on your local computer. Simulators allow flight code to control a computer modeled vehicle in a simulated \"world\". You can interact with this vehicle just as you might with a real vehicle, using QGroundControl, an offboard API such as ROS, or a radio controller/gamepad. Simulation is a quick, easy, and most importantly, safe way to test changes to your controller before attempting to fly in the real world. It is also a good way to start flying when you haven't yet got a vehicle to experiment with or dont want to damage it. From a Starling perspective, the MAVROS container does not distinguish between running on a real vehicle or running on SITL as both still speak the same version of MAVLINK. The MAVROS container internally handles connecting to the correct source.","title":"Software in the loop"},{"location":"simulation/#gazebo","text":"Alongisde the SITL, a physics engine is also required for it to run against. Together the simulation is often performed in lockstep where the SITL will generate a motion in one step based on the simulator state, follwed by the simulator advancing by one step based on that motion. In Starling, we primarily use the gazebo physics and visualisation engine as it is one of the most commonly out there currently in the robotics space. Starling is designed with simulator modularity in mind, and it's hoped that in the future other simulators will also be supported! Starling provides a number of containers which have Gazebo pre configured and installed, along with a web based interface for viewing the simulation in progress. In this tutorial, we will be using one container in particular.","title":"Gazebo"},{"location":"simulation/#brl-digital-double","text":"As well as simulating the vehicles themselves, it is also important to simulate the environment in which we are operating. For this tutorial we will be flying the Bristol Robotics Laboratory (BRL) flight arena, and therefore we provide a digital double of that space here , and it is contained within the following container: uobflightlabstarling/uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This will place you into a space where the exact measurements match the real world version of the flight arena. Flight arena is 15.6m x 11.8m x 5m (x, y, z) tall, origin is offset by (0.5, 0.7, 0.0) from space center. The coordinate space is x positive is up and y postivie is left (w.r.t the ascii figure). _________________________________ | | | | | | |_ L| |C| | | | |__|____________ | |___|_V_|___|___| | | _____ _____| |_ _____ ______|__E__|_____|","title":"BRL Digital Double"},{"location":"simulation/#running-the-local-simulator","text":"With all of that in mind, we can now run the full simulation of a single UAV in the flight arena locally on your machine. Go to your new Starling application, and you should see a deployment folder. Inside there exists a docker-compose.yml file. A docker compose file is used to specify the running of multiple containers in one go, instead of having to run a bunch of them manually! To ensure that you have the latest containers, we should pull all of the used ones from docker hub explicitly: docker-compose -f deployment/docker-compose.yml pull This can take a while, especially if the internet is slow. Once downloaded, you can then run the simulator stack with the up command: docker-compose -f deployment/docker-compose.yml up If you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml --pull start Note: depending on what you also have running, you may receive a port in use error. If it is the port for simhost (8080), rosbridge (9090) or the ui (3000), you can change it as <local_port>:<container_port> . Note: Stop the simulator with ctrl+c Once you have run, you should see a lot of text fly by in the terminal! Hopefully none of it is red... To access the simulator, go to localhost:8080 , and to access the simple UI, go to localhost:3000 . The UI contains a simple Go and Stop button which both send topics of /mission_start and /emergency_stop respectively.","title":"Running the local simulator"},{"location":"simulation/#what-is-in-the-local-simulation","text":"Awesome you now have the local simulator running... but what have you actually run? Let's take you through the docker compose file: uobflightlabstarling/starling-sim-iris-px4-flightarena : As mentioned is the gazebo image which contains the model of the flying arena, as well as the model of the UAV. On startup, it spawns the arena and spawns a single vehicle into it. uobflightlabstarling/starling-sim-px4-sitl : Is the container which runs the PX4 Software In The Loop mentioned earlier on. Throug the environment variables, it knows to connect to the gazebo container for physics, and then knows to expect the mavros container for offboard commands. uobflightlabstarling/starling-mavros : Is the container which runs mavros mentioned in a previous tutorial. It serves as the connection point between the SITL and your own controller code. uobflightlabstarling/rosbridge-suite : Is the gateway for web ros applications like the UI to connect to ROS. uobflightlabstarling/starling-ui-example : Is the example web application with a simple interface.","title":"What is in the local simulation"},{"location":"simulation/#inspecting-the-local-simulation","text":"To verify the functionality of the simulator, we can have a look at some of the ROS Topics that are being sent around. Let us do this by exec -ing into one of the containers. So again: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca5384b42f41 uobflightlabstarling/starling-mavros:nightly \"/ros_entrypoint.sh \u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:5760->5760/tcp deployment_mavros_1 633d71686da7 uobflightlabstarling/starling-sim-px4-sitl:nightly \"/entrypoint.sh /bin\u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:18570->18570/udp deployment_sitl_1 a462241ba16f uobflightlabstarling/starling-sim-iris-px4-flightarena:latest \"/entrypoint.sh ros2\u2026\" 9 seconds ago Up 8 seconds 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp deployment_simhost_1 51adc525e085 uobflightlabstarling/starling-ui-example:latest \"/ros_entrypoint.sh \u2026\" 29 minutes ago Up 8 seconds 9090/tcp, 0.0.0.0:3001->3000/tcp deployment_starling-ui-example_1 f1208345c980 uobflightlabstarling/rosbridge-suite:latest \"/ros_entrypoint.sh \u2026\" 36 minutes ago Up 9 seconds 0.0.0.0:9090->9090/tcp deployment_rosbridge-suite_1 Choosing the starling-mavros container, we can exec into that and run the following: docker exec -it ca5384b42f41 bash root@ca5384b42f41:/ros_ws# . /opt/ros/foxy/setup.bash root@ca5384b42f41:/ros_ws# ros2 topic list /client_count /clock /connected_clients /emergency_stop /link_states /model_states /parameter_events /performance_metrics /rosout /vehicle_1/mavlink/from /vehicle_1/mavlink/to /vehicle_1/mavros/battery /vehicle_1/mavros/distance_sensor/hrlv_ez4_sonar /vehicle_1/mavros/distance_sensor/lidarlite_laser /vehicle_1/mavros/distance_sensor/rangefinder /vehicle_1/mavros/distance_sensor/temperature /vehicle_1/mavros/extended_state /vehicle_1/mavros/global_position/global /vehicle_1/mavros/image/camera_image /vehicle_1/mavros/imu/data /vehicle_1/mavros/local_position/accel /vehicle_1/mavros/local_position/odom /vehicle_1/mavros/local_position/pose /vehicle_1/mavros/local_position/pose_cov /vehicle_1/mavros/local_position/velocity_body /vehicle_1/mavros/local_position/velocity_body_cov /vehicle_1/mavros/local_position/velocity_local /vehicle_1/mavros/manual_control/control /vehicle_1/mavros/manual_control/send /vehicle_1/mavros/mission/reached /vehicle_1/mavros/mission/waypoints /vehicle_1/mavros/px4flow/ground_distance /vehicle_1/mavros/px4flow/raw/optical_flow_rad /vehicle_1/mavros/safety_area /vehicle_1/mavros/setpoint_accel/accel /vehicle_1/mavros/setpoint_attitude/attitude /vehicle_1/mavros/setpoint_attitude/cmd_vel /vehicle_1/mavros/setpoint_attitude/thrust /vehicle_1/mavros/setpoint_position/global /vehicle_1/mavros/setpoint_position/global_to_local /vehicle_1/mavros/setpoint_position/local /vehicle_1/mavros/setpoint_raw/attitude /vehicle_1/mavros/setpoint_raw/global /vehicle_1/mavros/setpoint_raw/local /vehicle_1/mavros/setpoint_velocity/cmd_vel_unstamped /vehicle_1/mavros/state /vehicle_1/mavros/vision_pose/pose /vehicle_1/mavros/vision_pose/pose_cov /vehicle_1/mavros/vision_speed/speed_twist /vehicle_1/mavros/vision_speed/speed_vector This list a list of all the topics currently being broadcast onto the system. Similarly we can inspect the current list of nodes: root@ca5384b42f41:/ros_ws# ros2 node list /gazebo /gazebo_vehicle_state_plugin /motion_tracker_sim /rosapi /rosapi /rosbridge_websocket /vehicle_1/estop /vehicle_1/ros_bridge and many others. We can also have a look at some of the topics. For example, if we wanted to look at the state of a vehicle 1, we would have a look at /vehicle_1/mavros/local_posiiton/pose (Press ctrl+c to stop the stream). root@ca5384b42f41:/ros_ws# ros2 topic echo /vehicle_1/mavros/local_posiiton/pose --- header: stamp: sec: 1655741007 nanosec: 589603584 frame_id: map pose: position: x: -0.010252323932945728 y: -0.025252731516957283 z: -0.019200336188077927 orientation: x: -0.0019689216589022533 y: -0.0020565663184938785 z: 0.0005801513697525905 w: -0.9999958103477264 --- header: stamp: sec: 1655741007 nanosec: 617603584 frame_id: map pose: position: x: -0.01022176630795002 y: -0.02509368769824505 z: -0.018872130662202835 orientation: x: -0.0019977603981865205 y: -0.0021082978655832646 z: 0.0006137002611672492 w: -0.9999956417603324 --- ... Have a play around an investigate the other topics! Finally to stop the simulator, you can simply run ctrl+c in the terminal running the simulator.","title":"Inspecting the local simulation"},{"location":"simulation/#next-steps","text":"This tutorial should have introduced you to how UAV simulation works and the gazebo simulator we use in Starling. It should have also showed you how to run the simulator, so that you can test the controller you will be developing in the next part.","title":"Next Steps"},{"location":"testing_with_docker_compose/","text":"Local Testing with Docker Compose \u00b6 In this section we will see how to do local development and testing with the local simulation environment using docker-compose. This forms the first step of the Starling workflow. By the end of this tutorial, you should understand how to run your controller against the simulation containers. Local Testing with Docker Compose Running the Controller and the Simulator Together Verify your controller Connect the simulator Developing with the Simulator Next Steps Running the Controller and the Simulator Together \u00b6 Bringing together the previous couple of tutorials, we can run our developed controller against the simulator. Verify your controller \u00b6 First let us verify that our own controller is at least compiling properly. We should get something like the following, and then stop it using ctrl+c make run ... ---- controller base setup START ------------ VEHICLE_NAMESPACE not set, default to launchfile defaults ---- controller base setup END ------------ Sourcing local install setup.bash VEHICLE_MAVLINK_SYSID not set, default to 1 Running Onboard Controller [INFO] [launch]: All log files can be found below /root/.ros/log/2022-06-20-22-22-51-158267-9c4f7a240328-49 [INFO] [launch]: Default logging verbosity is set to INFO [INFO] [controller-1]: process started with pid [51] [controller-1] [INFO] [1655763771.265611400] [vehicle_1.controller]: Reset Internal Parameters and Trajectory Executor [controller-1] [INFO] [1655763771.265749100] [vehicle_1.controller]: Controller initialised [controller-1] [WARN] [1655763771.365796900] [vehicle_1.controller]: Waiting for vehicle state data [controller-1] [INFO] [1655763771.365888900] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [WARN] [1655763771.465746400] [vehicle_1.controller]: Waiting for vehicle state data ... If you have syntax errors and the like, please go back and fix them before continuing, it will save you time in the long run! The controller is currently waiting on system checks and vehicle state data. This means that it is not receiving any data from drone ros topics. Understandable as we have not yet run the simulator and connected it up! Connect the simulator \u00b6 Similar to previously, we can run the simulation stack provided for testing: docker-compose -f deployment/docker-compose.yml up or if you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml start # or to pull the images as well starling deploy -f deployment/docker-compose.yml start --pull To access the simulator, go to localhost:8080 , and to access the simple UI, go to localhost:3000 . In order for the controller to connect to the simulator, we need to find out which docker network the simulator is running on. To view the current docker networks, in a second terminal run docker network ls NETWORK ID NAME DRIVER SCOPE 4c2a6932e455 bridge bridge local 681c73eec26a deployment_default bridge local 1059b63b6f59 host host local We are interested in the network named <something>_default and not named bridge and host which are docker default networks. In our case deployment_default is the network created by docker compose when running the simulation stack. It should also be called deployment_default for you (the <something> is the parent folder of the docker compose file). Then re-run your controller with this new network. You can use the NETWORK variable from the Makefile make NETWORK=deployment_default run ... [controller-1] [INFO] [1655765539.785786200] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [INFO] [1655765539.816086500] [vehicle_1.controller]: Initial mavros state received [controller-1] [INFO] [1655765539.885724600] [vehicle_1.controller]: Initialisation Waiting on Mission Start [controller-1] [INFO] [1655765539.985731000] [vehicle_1.controller]: Initialisation Waiting on Mission Start ... You could also simply specify the --net=deployment_default option with normal docker run Success! It looks like the controller has received data from mavros and is currently waiting to start the mission! To advance the mission, you can try pressing the green mission start button on the web interface. The vehicle should then indicate it is trying to take off, and you should be able to see it move in the simulator interface! However you will notice that it gets stuck waiting for User Controller Ready. This is because it is waiting for a packet from the server with its initial location, but of course we have no server running so it never receives it! To remedy this, you can open up another terminal in order to run the server. As mentioned previously, this can be achieved by setting the environment variable OFFBOARD to true using the following syntax make NETWORK=deployment_default ENV=\"-e OFFBOARD=true\" run Repeating the previous steps to start the main controller on the network, we then get the following if we follow the instructions and press the go button every time the controller asks. Oh dear it looks like this example is almost there, but starts flying off of the circle erratically, how could this be! How do I develop this container without having to stop and start everything. Developing with the Simulator \u00b6 You may have noticed that we started the simulator, and your controller seperately as two distinct elements. You didn't have to modify any config files to add in your own controller either. This is one of the great benefits of our system as this designed separation allows the recreation of your user application without having to restart the main simulator! This holds as long as Your application has been run on the same network as the simulator Your application is written in such a way that it can be attached to the simulator at any time Your application hasn't put the simulator in an unrecoverable state! e.g. Flipped the vehicle upside down. Otherwise it is quite simple to simple make some changes to your own application and re-run your container using make ... run again without having to exit the simulator . Note: This also applies to the terminal running the offboard node! Since its reactive, you dont need restart that either. ROS will simply patch the connection when your onboard controller is restarted. And now finding the bug in my smExecute function, my controller now does what I expect it to do - fly in a circle! Next Steps \u00b6 Congrats! \ud83e\udd73 You hopefully now have a working and tested starling application. With luck, you now also have a better understanding of how to use Starling and its containers to quickly develop and prototype your controllers. However, we still have one part of the brief to go - the customer wanted a multi-drone application! In the next few tutorials we will take you through how to build, develop and test your application in a multi-drone setup which will take you closer to flying on the real drones at the BRL.","title":"7. Local testing with Docker-Compose"},{"location":"testing_with_docker_compose/#local-testing-with-docker-compose","text":"In this section we will see how to do local development and testing with the local simulation environment using docker-compose. This forms the first step of the Starling workflow. By the end of this tutorial, you should understand how to run your controller against the simulation containers. Local Testing with Docker Compose Running the Controller and the Simulator Together Verify your controller Connect the simulator Developing with the Simulator Next Steps","title":"Local Testing with Docker Compose"},{"location":"testing_with_docker_compose/#running-the-controller-and-the-simulator-together","text":"Bringing together the previous couple of tutorials, we can run our developed controller against the simulator.","title":"Running the Controller and the Simulator Together"},{"location":"testing_with_docker_compose/#verify-your-controller","text":"First let us verify that our own controller is at least compiling properly. We should get something like the following, and then stop it using ctrl+c make run ... ---- controller base setup START ------------ VEHICLE_NAMESPACE not set, default to launchfile defaults ---- controller base setup END ------------ Sourcing local install setup.bash VEHICLE_MAVLINK_SYSID not set, default to 1 Running Onboard Controller [INFO] [launch]: All log files can be found below /root/.ros/log/2022-06-20-22-22-51-158267-9c4f7a240328-49 [INFO] [launch]: Default logging verbosity is set to INFO [INFO] [controller-1]: process started with pid [51] [controller-1] [INFO] [1655763771.265611400] [vehicle_1.controller]: Reset Internal Parameters and Trajectory Executor [controller-1] [INFO] [1655763771.265749100] [vehicle_1.controller]: Controller initialised [controller-1] [WARN] [1655763771.365796900] [vehicle_1.controller]: Waiting for vehicle state data [controller-1] [INFO] [1655763771.365888900] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [WARN] [1655763771.465746400] [vehicle_1.controller]: Waiting for vehicle state data ... If you have syntax errors and the like, please go back and fix them before continuing, it will save you time in the long run! The controller is currently waiting on system checks and vehicle state data. This means that it is not receiving any data from drone ros topics. Understandable as we have not yet run the simulator and connected it up!","title":"Verify your controller"},{"location":"testing_with_docker_compose/#connect-the-simulator","text":"Similar to previously, we can run the simulation stack provided for testing: docker-compose -f deployment/docker-compose.yml up or if you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml start # or to pull the images as well starling deploy -f deployment/docker-compose.yml start --pull To access the simulator, go to localhost:8080 , and to access the simple UI, go to localhost:3000 . In order for the controller to connect to the simulator, we need to find out which docker network the simulator is running on. To view the current docker networks, in a second terminal run docker network ls NETWORK ID NAME DRIVER SCOPE 4c2a6932e455 bridge bridge local 681c73eec26a deployment_default bridge local 1059b63b6f59 host host local We are interested in the network named <something>_default and not named bridge and host which are docker default networks. In our case deployment_default is the network created by docker compose when running the simulation stack. It should also be called deployment_default for you (the <something> is the parent folder of the docker compose file). Then re-run your controller with this new network. You can use the NETWORK variable from the Makefile make NETWORK=deployment_default run ... [controller-1] [INFO] [1655765539.785786200] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [INFO] [1655765539.816086500] [vehicle_1.controller]: Initial mavros state received [controller-1] [INFO] [1655765539.885724600] [vehicle_1.controller]: Initialisation Waiting on Mission Start [controller-1] [INFO] [1655765539.985731000] [vehicle_1.controller]: Initialisation Waiting on Mission Start ... You could also simply specify the --net=deployment_default option with normal docker run Success! It looks like the controller has received data from mavros and is currently waiting to start the mission! To advance the mission, you can try pressing the green mission start button on the web interface. The vehicle should then indicate it is trying to take off, and you should be able to see it move in the simulator interface! However you will notice that it gets stuck waiting for User Controller Ready. This is because it is waiting for a packet from the server with its initial location, but of course we have no server running so it never receives it! To remedy this, you can open up another terminal in order to run the server. As mentioned previously, this can be achieved by setting the environment variable OFFBOARD to true using the following syntax make NETWORK=deployment_default ENV=\"-e OFFBOARD=true\" run Repeating the previous steps to start the main controller on the network, we then get the following if we follow the instructions and press the go button every time the controller asks. Oh dear it looks like this example is almost there, but starts flying off of the circle erratically, how could this be! How do I develop this container without having to stop and start everything.","title":"Connect the simulator"},{"location":"testing_with_docker_compose/#developing-with-the-simulator","text":"You may have noticed that we started the simulator, and your controller seperately as two distinct elements. You didn't have to modify any config files to add in your own controller either. This is one of the great benefits of our system as this designed separation allows the recreation of your user application without having to restart the main simulator! This holds as long as Your application has been run on the same network as the simulator Your application is written in such a way that it can be attached to the simulator at any time Your application hasn't put the simulator in an unrecoverable state! e.g. Flipped the vehicle upside down. Otherwise it is quite simple to simple make some changes to your own application and re-run your container using make ... run again without having to exit the simulator . Note: This also applies to the terminal running the offboard node! Since its reactive, you dont need restart that either. ROS will simply patch the connection when your onboard controller is restarted. And now finding the bug in my smExecute function, my controller now does what I expect it to do - fly in a circle!","title":"Developing with the Simulator"},{"location":"testing_with_docker_compose/#next-steps","text":"Congrats! \ud83e\udd73 You hopefully now have a working and tested starling application. With luck, you now also have a better understanding of how to use Starling and its containers to quickly develop and prototype your controllers. However, we still have one part of the brief to go - the customer wanted a multi-drone application! In the next few tutorials we will take you through how to build, develop and test your application in a multi-drone setup which will take you closer to flying on the real drones at the BRL.","title":"Next Steps"},{"location":"testing_with_kind/","text":"Local Integration testing with KinD Digital Double \u00b6","title":"9. Local Integration testing with KinD Digital Double"},{"location":"testing_with_kind/#local-integration-testing-with-kind-digital-double","text":"","title":"Local Integration testing with KinD Digital Double"}]}